[
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "MoleculeNet",
        "importPath": "torch_geometric.datasets",
        "description": "torch_geometric.datasets",
        "isExtraImport": true,
        "detail": "torch_geometric.datasets",
        "documentation": {}
    },
    {
        "label": "MoleculeNet",
        "importPath": "torch_geometric.datasets",
        "description": "torch_geometric.datasets",
        "isExtraImport": true,
        "detail": "torch_geometric.datasets",
        "documentation": {}
    },
    {
        "label": "MoleculeNet",
        "importPath": "torch_geometric.datasets",
        "description": "torch_geometric.datasets",
        "isExtraImport": true,
        "detail": "torch_geometric.datasets",
        "documentation": {}
    },
    {
        "label": "MoleculeNet",
        "importPath": "torch_geometric.datasets",
        "description": "torch_geometric.datasets",
        "isExtraImport": true,
        "detail": "torch_geometric.datasets",
        "documentation": {}
    },
    {
        "label": "MoleculeNet",
        "importPath": "torch_geometric.datasets",
        "description": "torch_geometric.datasets",
        "isExtraImport": true,
        "detail": "torch_geometric.datasets",
        "documentation": {}
    },
    {
        "label": "GATv2Conv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "global_mean_pool",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "EdgeConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "GCNConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "global_mean_pool",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "EdgeConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "GCNConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "global_mean_pool",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "EdgeConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "MessagePassing",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "GCNConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "global_mean_pool",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "EdgeConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "NNConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "torch.utils.tensorboard",
        "description": "torch.utils.tensorboard",
        "isExtraImport": true,
        "detail": "torch.utils.tensorboard",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "torch.utils.tensorboard",
        "description": "torch.utils.tensorboard",
        "isExtraImport": true,
        "detail": "torch.utils.tensorboard",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "torch.utils.tensorboard",
        "description": "torch.utils.tensorboard",
        "isExtraImport": true,
        "detail": "torch.utils.tensorboard",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "torch.utils.tensorboard",
        "description": "torch.utils.tensorboard",
        "isExtraImport": true,
        "detail": "torch.utils.tensorboard",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.loader",
        "description": "torch_geometric.loader",
        "isExtraImport": true,
        "detail": "torch_geometric.loader",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Chem",
        "importPath": "rdkit",
        "description": "rdkit",
        "isExtraImport": true,
        "detail": "rdkit",
        "documentation": {}
    },
    {
        "label": "Draw",
        "importPath": "rdkit.Chem",
        "description": "rdkit.Chem",
        "isExtraImport": true,
        "detail": "rdkit.Chem",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "display",
        "importPath": "IPython.display",
        "description": "IPython.display",
        "isExtraImport": true,
        "detail": "IPython.display",
        "documentation": {}
    },
    {
        "label": "networkx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "networkx",
        "description": "networkx",
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "to_networkx",
        "importPath": "torch_geometric.utils",
        "description": "torch_geometric.utils",
        "isExtraImport": true,
        "detail": "torch_geometric.utils",
        "documentation": {}
    },
    {
        "label": "tabulate",
        "importPath": "tabulate",
        "description": "tabulate",
        "isExtraImport": true,
        "detail": "tabulate",
        "documentation": {}
    },
    {
        "label": "GATTox21",
        "kind": 6,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "class GATTox21(torch.nn.Module):\n    def __init__(self, num_node_features, num_edge_features):\n        super(GATTox21, self).__init__()\n        # Initial node embedding\n        self.node_embedding = torch.nn.Linear(num_node_features, 64)\n        # GAT layers with edge features\n        self.conv1 = GATv2Conv(64, 128, edge_dim=num_edge_features, heads=4)\n        self.conv2 = GATv2Conv(128 * 4, 64, edge_dim=num_edge_features, heads=2)\n        self.conv3 = GATv2Conv(64 * 2, 32, edge_dim=num_edge_features, heads=1)\n        # Batch normalization layers",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "def calculate_metrics(y_true, y_pred, mask):\n    \"\"\"Calculate various performance metrics.\"\"\"\n    # Convert predictions to binary (0/1)\n    y_pred_binary = (y_pred > 0.5).float()\n    # Apply mask to get valid predictions\n    y_true = y_true[mask]\n    y_pred = y_pred[mask]\n    y_pred_binary = y_pred_binary[mask]\n    # Calculate metrics\n    correct = (y_pred_binary == y_true).float().sum()",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "def train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        if data.edge_weight is not None:\n            data.edge_weight = data.edge_weight.float()",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "validate",
        "kind": 2,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "def validate(model, val_loader, device, epoch):\n    model.eval()\n    total_loss = 0\n    all_metrics = []\n    for data in val_loader:\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n        target = data.y[:, :12].float()",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "current_time",
        "kind": 5,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "current_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\nlog_dir = f'runs/GAT_Tox21_500_epochs{current_time}'\nwriter = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "log_dir",
        "kind": 5,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "log_dir = f'runs/GAT_Tox21_500_epochs{current_time}'\nwriter = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "writer",
        "kind": 5,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "writer = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        if data.edge_weight is not None:",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "dataset",
        "kind": 5,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "dataset = MoleculeNet(root='data/TOX21', name='TOX21')\n# Split dataset into train and test 0.8\ntrain_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GATTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "train_dataset",
        "kind": 5,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "train_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GATTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "test_dataset",
        "kind": 5,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "test_dataset = dataset[int(0.8 * len(dataset)):]\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GATTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "train_loader",
        "kind": 5,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GATTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', \n    'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "test_loader",
        "kind": 5,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GATTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', \n    'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'\n]",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GATTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', \n    'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'\n]\ntask_descriptions = [",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "model = GATTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', \n    'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'\n]\ntask_descriptions = [\n    'Androgen Receptor',",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', \n    'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'\n]\ntask_descriptions = [\n    'Androgen Receptor',\n    'Androgen Receptor Ligand Binding Domain',",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "task_names",
        "kind": 5,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "task_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', \n    'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'\n]\ntask_descriptions = [\n    'Androgen Receptor',\n    'Androgen Receptor Ligand Binding Domain',\n    'Aryl Hydrocarbon Receptor',\n    'Aromatase',\n    'Estrogen Receptor',",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "task_descriptions",
        "kind": 5,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "task_descriptions = [\n    'Androgen Receptor',\n    'Androgen Receptor Ligand Binding Domain',\n    'Aryl Hydrocarbon Receptor',\n    'Aromatase',\n    'Estrogen Receptor',\n    'Estrogen Receptor Ligand Binding Domain',\n    'Peroxisome Proliferator-Activated Receptor Gamma',\n    'Antioxidant Response Element',\n    'ATAD5',",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "num_epochs",
        "kind": 5,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "num_epochs = 500\nbest_val_auc = 0\nfor epoch in range(num_epochs):\n    train_metrics = train(model, train_loader, optimizer, device, epoch)\n    val_metrics = validate(model, test_loader, device, epoch)\n    print(f'Epoch {epoch:03d}:')\n    print('Training metrics:')\n    for k, v in train_metrics.items():\n        print(f'  {k}: {v:.4f}')\n    print('Validation metrics:')",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "best_val_auc",
        "kind": 5,
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "peekOfCode": "best_val_auc = 0\nfor epoch in range(num_epochs):\n    train_metrics = train(model, train_loader, optimizer, device, epoch)\n    val_metrics = validate(model, test_loader, device, epoch)\n    print(f'Epoch {epoch:03d}:')\n    print('Training metrics:')\n    for k, v in train_metrics.items():\n        print(f'  {k}: {v:.4f}')\n    print('Validation metrics:')\n    for k, v in val_metrics.items():",
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "GCNTox21",
        "kind": 6,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "class GCNTox21(torch.nn.Module):\n    def __init__(self, num_node_features, num_edge_features):\n        super(GCNTox21, self).__init__()\n        # Edge embedding layer\n        self.edge_embedding = torch.nn.Linear(num_edge_features, 32)\n        # Node embedding layer\n        self.node_embedding = torch.nn.Linear(num_node_features, 64)\n        # Define MLPs for EdgeConv layers\n        self.mlp1 = torch.nn.Sequential(\n            torch.nn.Linear(2 * 64, 128),  # Only node features for EdgeConv",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "def calculate_metrics(y_true, y_pred, mask):\n    \"\"\"Calculate various performance metrics.\"\"\"\n    # Convert predictions to binary (0/1)\n    y_pred_binary = (y_pred > 0.5).float()\n    # Apply mask to get valid predictions\n    y_true = y_true[mask]\n    y_pred = y_pred[mask]\n    y_pred_binary = y_pred_binary[mask]\n    # Calculate metrics\n    correct = (y_pred_binary == y_true).float().sum()",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "def train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        if data.edge_weight is not None:\n            data.edge_weight = data.edge_weight.float()",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "validate",
        "kind": 2,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "def validate(model, val_loader, device, epoch):\n    model.eval()\n    total_loss = 0\n    all_metrics = []\n    for data in val_loader:\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n        target = data.y[:, :12].float()",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "current_time",
        "kind": 5,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "current_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\nlog_dir = f'runs/GCN_node_tox21_{current_time}'\nwriter = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "log_dir",
        "kind": 5,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "log_dir = f'runs/GCN_node_tox21_{current_time}'\nwriter = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "writer",
        "kind": 5,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "writer = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        if data.edge_weight is not None:",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "dataset",
        "kind": 5,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "dataset = MoleculeNet(root='data/TOX21', name='TOX21')\n# Split dataset into train and test 0.8\ntrain_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "train_dataset",
        "kind": 5,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "train_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "test_dataset",
        "kind": 5,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "test_dataset = dataset[int(0.8 * len(dataset)):]\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "train_loader",
        "kind": 5,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "test_loader",
        "kind": 5,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "model = GCNTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', ",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', \n    'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "model_summary_path",
        "kind": 5,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "model_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', \n    'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'\n]\ntask_descriptions = [",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "task_names",
        "kind": 5,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "task_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', \n    'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'\n]\ntask_descriptions = [\n    'Androgen Receptor',\n    'Androgen Receptor Ligand Binding Domain',\n    'Aryl Hydrocarbon Receptor',\n    'Aromatase',\n    'Estrogen Receptor',",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "task_descriptions",
        "kind": 5,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "task_descriptions = [\n    'Androgen Receptor',\n    'Androgen Receptor Ligand Binding Domain',\n    'Aryl Hydrocarbon Receptor',\n    'Aromatase',\n    'Estrogen Receptor',\n    'Estrogen Receptor Ligand Binding Domain',\n    'Peroxisome Proliferator-Activated Receptor Gamma',\n    'Antioxidant Response Element',\n    'ATAD5',",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "num_epochs",
        "kind": 5,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "num_epochs = 100\nbest_val_auc = 0\nfor epoch in range(num_epochs):\n    train_metrics = train(model, train_loader, optimizer, device, epoch)\n    val_metrics = validate(model, test_loader, device, epoch)\n    print(f'Epoch {epoch:03d}:')\n    print('Training metrics:')\n    for k, v in train_metrics.items():\n        print(f'  {k}: {v:.4f}')\n    print('Validation metrics:')",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "best_val_auc",
        "kind": 5,
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "peekOfCode": "best_val_auc = 0\nfor epoch in range(num_epochs):\n    train_metrics = train(model, train_loader, optimizer, device, epoch)\n    val_metrics = validate(model, test_loader, device, epoch)\n    print(f'Epoch {epoch:03d}:')\n    print('Training metrics:')\n    for k, v in train_metrics.items():\n        print(f'  {k}: {v:.4f}')\n    print('Validation metrics:')\n    for k, v in val_metrics.items():",
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "PairwiseEdgeConv",
        "kind": 6,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "class PairwiseEdgeConv(MessagePassing):\n    def __init__(self, in_channels, edge_channels, out_channels):\n        super(PairwiseEdgeConv, self).__init__(aggr='mean')\n        # MLP for processing concatenated features\n        # Input: [node_i || node_j || edge_attr]\n        self.mlp = torch.nn.Sequential(\n            torch.nn.Linear(2 * in_channels + edge_channels, out_channels * 2),\n            torch.nn.ReLU(),\n            torch.nn.Linear(out_channels * 2, out_channels)\n        )",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "GCNTox21",
        "kind": 6,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "class GCNTox21(torch.nn.Module):\n    def __init__(self, num_node_features, num_edge_features):\n        super(GCNTox21, self).__init__()\n        # Feature dimensions\n        self.node_hidden = 64\n        self.edge_hidden = 16\n        # Edge embedding layer\n        self.edge_embedding = torch.nn.Sequential(\n            torch.nn.Linear(num_edge_features, self.edge_hidden),\n            torch.nn.ReLU()",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "def calculate_metrics(y_true, y_pred, mask):\n    \"\"\"Calculate various performance metrics.\"\"\"\n    # Convert predictions to binary (0/1)\n    y_pred_binary = (y_pred > 0.5).float()\n    # Apply mask to get valid predictions\n    y_true = y_true[mask]\n    y_pred = y_pred[mask]\n    y_pred_binary = y_pred_binary[mask]\n    # Calculate metrics\n    correct = (y_pred_binary == y_true).float().sum()",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "def train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        if data.edge_weight is not None:\n            data.edge_weight = data.edge_weight.float()",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "validate",
        "kind": 2,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "def validate(model, val_loader, device, epoch):\n    model.eval()\n    total_loss = 0\n    all_metrics = []\n    for data in val_loader:\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n        target = data.y[:, :12].float()",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "current_time",
        "kind": 5,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "current_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\nlog_dir = f'runs/GCN_tox21_{current_time}'\nwriter = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "log_dir",
        "kind": 5,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "log_dir = f'runs/GCN_tox21_{current_time}'\nwriter = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "writer",
        "kind": 5,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "writer = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        if data.edge_weight is not None:",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "dataset",
        "kind": 5,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "dataset = MoleculeNet(root='data/TOX21', name='TOX21')\n# Split dataset into train and test 0.8\ntrain_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "train_dataset",
        "kind": 5,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "train_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "test_dataset",
        "kind": 5,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "test_dataset = dataset[int(0.8 * len(dataset)):]\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "train_loader",
        "kind": 5,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "test_loader",
        "kind": 5,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "model = GCNTox21(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', ",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', \n    'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "model_summary_path",
        "kind": 5,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "model_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', \n    'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'\n]\ntask_descriptions = [",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "task_names",
        "kind": 5,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "task_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', \n    'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'\n]\ntask_descriptions = [\n    'Androgen Receptor',\n    'Androgen Receptor Ligand Binding Domain',\n    'Aryl Hydrocarbon Receptor',\n    'Aromatase',\n    'Estrogen Receptor',",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "task_descriptions",
        "kind": 5,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "task_descriptions = [\n    'Androgen Receptor',\n    'Androgen Receptor Ligand Binding Domain',\n    'Aryl Hydrocarbon Receptor',\n    'Aromatase',\n    'Estrogen Receptor',\n    'Estrogen Receptor Ligand Binding Domain',\n    'Peroxisome Proliferator-Activated Receptor Gamma',\n    'Antioxidant Response Element',\n    'ATAD5',",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "num_epochs",
        "kind": 5,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "num_epochs = 100\nbest_val_auc = 0\nfor epoch in range(num_epochs):\n    train_metrics = train(model, train_loader, optimizer, device, epoch)\n    val_metrics = validate(model, test_loader, device, epoch)\n    print(f'Epoch {epoch:03d}:')\n    print('Training metrics:')\n    for k, v in train_metrics.items():\n        print(f'  {k}: {v:.4f}')\n    print('Validation metrics:')",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "best_val_auc",
        "kind": 5,
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "peekOfCode": "best_val_auc = 0\nfor epoch in range(num_epochs):\n    train_metrics = train(model, train_loader, optimizer, device, epoch)\n    val_metrics = validate(model, test_loader, device, epoch)\n    print(f'Epoch {epoch:03d}:')\n    print('Training metrics:')\n    for k, v in train_metrics.items():\n        print(f'  {k}: {v:.4f}')\n    print('Validation metrics:')\n    for k, v in val_metrics.items():",
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "GCNTox21NNConv",
        "kind": 6,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "class GCNTox21NNConv(torch.nn.Module):\n    def __init__(self, num_node_features, num_edge_features):\n        super(GCNTox21NNConv, self).__init__()\n        # Edge embedding layer\n        self.edge_embedding = torch.nn.Linear(num_edge_features, 32)\n        # Node embedding layer\n        self.node_embedding = torch.nn.Linear(num_node_features, 64)\n        # Define MLPs for NNConv layers\n        self.mlp1 = torch.nn.Sequential(\n            torch.nn.Linear(32, 128),",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "def calculate_metrics(y_true, y_pred, mask):\n    \"\"\"Calculate various performance metrics.\"\"\"\n    # Convert predictions to binary (0/1)\n    y_pred_binary = (y_pred > 0.5).float()\n    # Apply mask to get valid predictions\n    y_true = y_true[mask]\n    y_pred = y_pred[mask]\n    y_pred_binary = y_pred_binary[mask]\n    # Calculate metrics\n    correct = (y_pred_binary == y_true).float().sum()",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "def train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        if data.edge_weight is not None:\n            data.edge_weight = data.edge_weight.float()",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "validate",
        "kind": 2,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "def validate(model, val_loader, device, epoch):\n    model.eval()\n    total_loss = 0\n    all_metrics = []\n    for data in val_loader:\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n        target = data.y[:, :12].float()",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "current_time",
        "kind": 5,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "current_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\nlog_dir = f'runs/NNConv_{current_time}'\nwriter = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "log_dir",
        "kind": 5,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "log_dir = f'runs/NNConv_{current_time}'\nwriter = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "writer",
        "kind": 5,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "writer = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        if data.edge_weight is not None:",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "dataset",
        "kind": 5,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "dataset = MoleculeNet(root='data/TOX21', name='TOX21')\n# Split dataset into train and test 0.8\ntrain_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21NNConv(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "train_dataset",
        "kind": 5,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "train_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21NNConv(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "test_dataset",
        "kind": 5,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "test_dataset = dataset[int(0.8 * len(dataset)):]\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21NNConv(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "train_loader",
        "kind": 5,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21NNConv(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "test_loader",
        "kind": 5,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21NNConv(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNTox21NNConv(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "model = GCNTox21NNConv(dataset[0].num_node_features, dataset[0].num_edge_features).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', ",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# Save model summary\nmodel_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', \n    'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "model_summary_path",
        "kind": 5,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "model_summary_path = f'{log_dir}/model_summary.txt'\nwith open(model_summary_path, 'w') as f:\n    f.write(str(model))\n# Print the 12 toxicity tasks we're predicting along with their descriptions\nprint(\"Predicting the following toxicity tasks:\")\ntask_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', \n    'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'\n]\ntask_descriptions = [",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "task_names",
        "kind": 5,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "task_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', \n    'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'\n]\ntask_descriptions = [\n    'Androgen Receptor',\n    'Androgen Receptor Ligand Binding Domain',\n    'Aryl Hydrocarbon Receptor',\n    'Aromatase',\n    'Estrogen Receptor',",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "task_descriptions",
        "kind": 5,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "task_descriptions = [\n    'Androgen Receptor',\n    'Androgen Receptor Ligand Binding Domain',\n    'Aryl Hydrocarbon Receptor',\n    'Aromatase',\n    'Estrogen Receptor',\n    'Estrogen Receptor Ligand Binding Domain',\n    'Peroxisome Proliferator-Activated Receptor Gamma',\n    'Antioxidant Response Element',\n    'ATAD5',",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "num_epochs",
        "kind": 5,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "num_epochs = 100\nbest_val_auc = 0\nfor epoch in range(num_epochs):\n    train_metrics = train(model, train_loader, optimizer, device, epoch)\n    val_metrics = validate(model, test_loader, device, epoch)\n    print(f'Epoch {epoch:03d}:')\n    print('Training metrics:')\n    for k, v in train_metrics.items():\n        print(f'  {k}: {v:.4f}')\n    print('Validation metrics:')",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "best_val_auc",
        "kind": 5,
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "peekOfCode": "best_val_auc = 0\nfor epoch in range(num_epochs):\n    train_metrics = train(model, train_loader, optimizer, device, epoch)\n    val_metrics = validate(model, test_loader, device, epoch)\n    print(f'Epoch {epoch:03d}:')\n    print('Training metrics:')\n    for k, v in train_metrics.items():\n        print(f'  {k}: {v:.4f}')\n    print('Validation metrics:')\n    for k, v in val_metrics.items():",
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "dataset",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "dataset = MoleculeNet(root='data/TOX21', name='TOX21')\ndataset.get_summary()\n#%% Basic Dataset Statistics\nprint(\"\\n=== Basic Dataset Statistics ===\")\nprint(f\"Total number of molecules: {len(dataset)}\")\nprint(f\"Number of node features: {dataset.num_node_features}\")\nprint(f\"Number of edge features: {dataset.num_edge_features}\")\nprint(f\"Number of tasks: {dataset.num_classes}\")\n#%% Graph Statistics\nprint(\"\\n=== Graph Statistics ===\")",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "n_nodes",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "n_nodes = []\nn_edges = []\nnode_degrees = []\nfor data in tqdm(dataset, desc=\"Analyzing graphs\"):\n    n_nodes.append(data.num_nodes)\n    n_edges.append(data.num_edges)\n    degrees = torch.bincount(data.edge_index[0])\n    node_degrees.extend(degrees.tolist())\nprint(f\"Average number of nodes: {np.mean(n_nodes):.2f} ± {np.std(n_nodes):.2f}\")\nprint(f\"Average number of edges: {np.mean(n_edges):.2f} ± {np.std(n_edges):.2f}\")",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "n_edges",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "n_edges = []\nnode_degrees = []\nfor data in tqdm(dataset, desc=\"Analyzing graphs\"):\n    n_nodes.append(data.num_nodes)\n    n_edges.append(data.num_edges)\n    degrees = torch.bincount(data.edge_index[0])\n    node_degrees.extend(degrees.tolist())\nprint(f\"Average number of nodes: {np.mean(n_nodes):.2f} ± {np.std(n_nodes):.2f}\")\nprint(f\"Average number of edges: {np.mean(n_edges):.2f} ± {np.std(n_edges):.2f}\")\nprint(f\"Average node degree: {np.mean(node_degrees):.2f} ± {np.std(node_degrees):.2f}\")",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "node_degrees",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "node_degrees = []\nfor data in tqdm(dataset, desc=\"Analyzing graphs\"):\n    n_nodes.append(data.num_nodes)\n    n_edges.append(data.num_edges)\n    degrees = torch.bincount(data.edge_index[0])\n    node_degrees.extend(degrees.tolist())\nprint(f\"Average number of nodes: {np.mean(n_nodes):.2f} ± {np.std(n_nodes):.2f}\")\nprint(f\"Average number of edges: {np.mean(n_edges):.2f} ± {np.std(n_edges):.2f}\")\nprint(f\"Average node degree: {np.mean(node_degrees):.2f} ± {np.std(node_degrees):.2f}\")\n#%% Visualize distributions",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "node_features",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "node_features = torch.cat([data.x for data in dataset], dim=0).float()\nprint(\"Node Features Statistics:\")\nprint(f\"Feature dimensionality: {node_features.shape[1]}\")\n# Calculate feature statistics\nfeature_means = node_features.mean(dim=0)\nfeature_stds = node_features.std(dim=0)\n#%% Plot feature statistics\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 2, 1)\nplt.bar(range(len(feature_means)), feature_means)",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "feature_means",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "feature_means = node_features.mean(dim=0)\nfeature_stds = node_features.std(dim=0)\n#%% Plot feature statistics\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 2, 1)\nplt.bar(range(len(feature_means)), feature_means)\nplt.title('Mean Values of Node Features')\nplt.xlabel('Feature Index')\nplt.ylabel('Mean Value')\nplt.subplot(1, 2, 2)",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "feature_stds",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "feature_stds = node_features.std(dim=0)\n#%% Plot feature statistics\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 2, 1)\nplt.bar(range(len(feature_means)), feature_means)\nplt.title('Mean Values of Node Features')\nplt.xlabel('Feature Index')\nplt.ylabel('Mean Value')\nplt.subplot(1, 2, 2)\nplt.bar(range(len(feature_stds)), feature_stds)",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "all_labels",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "all_labels = torch.stack([data.y for data in dataset]).squeeze().numpy()\n# Define task names\ntask_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER',\n    'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5',\n    'SR-HSE', 'SR-MMP', 'SR-p53'\n]\n# Calculate correlation matrix (ignoring missing values)\ncorrelation_matrix = np.zeros((len(task_names), len(task_names)))\nfor i in range(len(task_names)):",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "task_names",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "task_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER',\n    'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5',\n    'SR-HSE', 'SR-MMP', 'SR-p53'\n]\n# Calculate correlation matrix (ignoring missing values)\ncorrelation_matrix = np.zeros((len(task_names), len(task_names)))\nfor i in range(len(task_names)):\n    for j in range(len(task_names)):\n        # Get valid indices (where both tasks have values)",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "correlation_matrix",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "correlation_matrix = np.zeros((len(task_names), len(task_names)))\nfor i in range(len(task_names)):\n    for j in range(len(task_names)):\n        # Get valid indices (where both tasks have values)\n        valid_indices = ~np.isnan(all_labels[:, i]) & ~np.isnan(all_labels[:, j])\n        if valid_indices.sum() > 0:\n            correlation_matrix[i, j] = np.corrcoef(\n                all_labels[valid_indices, i],\n                all_labels[valid_indices, j]\n            )[0, 1]",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "missing_values",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "missing_values = []\nfor i, task in enumerate(task_names):\n    # Count missing values\n    missing = np.isnan(all_labels[:, i]).sum()\n    missing_values.append(missing)\nfor i, task in enumerate(task_names):\n    valid_labels = all_labels[:, i][~np.isnan(all_labels[:, i])]\n    pos_rate = (valid_labels == 1).mean() if len(valid_labels) > 0 else 0\n    missing_rate = missing_values[i] / len(dataset)\n    print(f\"\\n{task}:\")",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "all_labels",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "all_labels = np.array([data.y for data in dataset])\nprint(f\"Shape of all_labels: {all_labels.shape}\")\nfor i in range(all_labels.shape[1]):\n    missing = np.isnan(all_labels[:, i]).sum()\n    print(f\"Missing values in column {i}: {missing}\")\n#%% Visualize a sample of molecules\nprint(\"\\n=== Visualize Sample Molecules ===\")\nsample_molecules = [dataset[i] for i in range(10)]\nsample_smiles = [data.smiles for data in sample_molecules]\nsample_mols = [Chem.MolFromSmiles(smiles) for smiles in sample_smiles]",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "sample_molecules",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "sample_molecules = [dataset[i] for i in range(10)]\nsample_smiles = [data.smiles for data in sample_molecules]\nsample_mols = [Chem.MolFromSmiles(smiles) for smiles in sample_smiles]\nimg = Draw.MolsToGridImage(sample_mols, molsPerRow=5, subImgSize=(200, 200))\ndisplay(img)\n#%% Visualize the graph of a sample molecule !!! test\nprint(\"\\n=== Visualize Graph of a Sample Molecule ===\")\nsample_data = dataset[1]  # Take the first molecule as an example\nG = to_networkx(sample_data, node_attrs=['x'], edge_attrs=['edge_attr'])\n# Plot the graph",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "sample_smiles",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "sample_smiles = [data.smiles for data in sample_molecules]\nsample_mols = [Chem.MolFromSmiles(smiles) for smiles in sample_smiles]\nimg = Draw.MolsToGridImage(sample_mols, molsPerRow=5, subImgSize=(200, 200))\ndisplay(img)\n#%% Visualize the graph of a sample molecule !!! test\nprint(\"\\n=== Visualize Graph of a Sample Molecule ===\")\nsample_data = dataset[1]  # Take the first molecule as an example\nG = to_networkx(sample_data, node_attrs=['x'], edge_attrs=['edge_attr'])\n# Plot the graph\nplt.figure(figsize=(10, 10))",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "sample_mols",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "sample_mols = [Chem.MolFromSmiles(smiles) for smiles in sample_smiles]\nimg = Draw.MolsToGridImage(sample_mols, molsPerRow=5, subImgSize=(200, 200))\ndisplay(img)\n#%% Visualize the graph of a sample molecule !!! test\nprint(\"\\n=== Visualize Graph of a Sample Molecule ===\")\nsample_data = dataset[1]  # Take the first molecule as an example\nG = to_networkx(sample_data, node_attrs=['x'], edge_attrs=['edge_attr'])\n# Plot the graph\nplt.figure(figsize=(10, 10))\npos = nx.spring_layout(G)",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "img = Draw.MolsToGridImage(sample_mols, molsPerRow=5, subImgSize=(200, 200))\ndisplay(img)\n#%% Visualize the graph of a sample molecule !!! test\nprint(\"\\n=== Visualize Graph of a Sample Molecule ===\")\nsample_data = dataset[1]  # Take the first molecule as an example\nG = to_networkx(sample_data, node_attrs=['x'], edge_attrs=['edge_attr'])\n# Plot the graph\nplt.figure(figsize=(10, 10))\npos = nx.spring_layout(G)\nnx.draw(G, pos, with_labels=True, node_color='skyblue', edge_color='gray', node_size=500, font_size=10)",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "sample_data",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "sample_data = dataset[1]  # Take the first molecule as an example\nG = to_networkx(sample_data, node_attrs=['x'], edge_attrs=['edge_attr'])\n# Plot the graph\nplt.figure(figsize=(10, 10))\npos = nx.spring_layout(G)\nnx.draw(G, pos, with_labels=True, node_color='skyblue', edge_color='gray', node_size=500, font_size=10)\n# Draw node labels\nnode_labels = {i: f\"{i}\\n{G.nodes[i]['x']}\" for i in G.nodes}\nnx.draw_networkx_labels(G, pos, labels=node_labels, font_size=8)\n# Draw edge labels",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "G",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "G = to_networkx(sample_data, node_attrs=['x'], edge_attrs=['edge_attr'])\n# Plot the graph\nplt.figure(figsize=(10, 10))\npos = nx.spring_layout(G)\nnx.draw(G, pos, with_labels=True, node_color='skyblue', edge_color='gray', node_size=500, font_size=10)\n# Draw node labels\nnode_labels = {i: f\"{i}\\n{G.nodes[i]['x']}\" for i in G.nodes}\nnx.draw_networkx_labels(G, pos, labels=node_labels, font_size=8)\n# Draw edge labels\nedge_labels = {(i, j): f\"{G.edges[i, j]['edge_attr']}\" for i, j in G.edges}",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "pos",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "pos = nx.spring_layout(G)\nnx.draw(G, pos, with_labels=True, node_color='skyblue', edge_color='gray', node_size=500, font_size=10)\n# Draw node labels\nnode_labels = {i: f\"{i}\\n{G.nodes[i]['x']}\" for i in G.nodes}\nnx.draw_networkx_labels(G, pos, labels=node_labels, font_size=8)\n# Draw edge labels\nedge_labels = {(i, j): f\"{G.edges[i, j]['edge_attr']}\" for i, j in G.edges}\nnx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n# Create a legend for node attributes with actual feature names\nnode_feature_names = ['Atomic Number', 'Chirality', 'Degree', 'Formal Charge', 'Num Hs', 'Hybridization']",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "node_labels",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "node_labels = {i: f\"{i}\\n{G.nodes[i]['x']}\" for i in G.nodes}\nnx.draw_networkx_labels(G, pos, labels=node_labels, font_size=8)\n# Draw edge labels\nedge_labels = {(i, j): f\"{G.edges[i, j]['edge_attr']}\" for i, j in G.edges}\nnx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n# Create a legend for node attributes with actual feature names\nnode_feature_names = ['Atomic Number', 'Chirality', 'Degree', 'Formal Charge', 'Num Hs', 'Hybridization']\nnode_attr_legend = {i: node_feature_names[i] for i in range(len(node_feature_names))}\nnode_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in node_attr_legend.items()])\n# Create a legend for edge attributes with actual feature names",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "edge_labels",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "edge_labels = {(i, j): f\"{G.edges[i, j]['edge_attr']}\" for i, j in G.edges}\nnx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n# Create a legend for node attributes with actual feature names\nnode_feature_names = ['Atomic Number', 'Chirality', 'Degree', 'Formal Charge', 'Num Hs', 'Hybridization']\nnode_attr_legend = {i: node_feature_names[i] for i in range(len(node_feature_names))}\nnode_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in node_attr_legend.items()])\n# Create a legend for edge attributes with actual feature names\nedge_feature_names = ['Bond Type', 'Bond Stereo']\nedge_attr_legend = {i: edge_feature_names[i] for i in range(len(edge_feature_names))}\nedge_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in edge_attr_legend.items()])",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "node_feature_names",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "node_feature_names = ['Atomic Number', 'Chirality', 'Degree', 'Formal Charge', 'Num Hs', 'Hybridization']\nnode_attr_legend = {i: node_feature_names[i] for i in range(len(node_feature_names))}\nnode_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in node_attr_legend.items()])\n# Create a legend for edge attributes with actual feature names\nedge_feature_names = ['Bond Type', 'Bond Stereo']\nedge_attr_legend = {i: edge_feature_names[i] for i in range(len(edge_feature_names))}\nedge_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in edge_attr_legend.items()])\n# Display the legends\nplt.gcf().text(0.02, 0.5, f\"Node Attributes:\\n{node_attr_legend_text}\", fontsize=10, verticalalignment='center')\nplt.gcf().text(0.98, 0.5, f\"Edge Attributes:\\n{edge_attr_legend_text}\", fontsize=10, verticalalignment='center', horizontalalignment='right')",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "node_attr_legend",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "node_attr_legend = {i: node_feature_names[i] for i in range(len(node_feature_names))}\nnode_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in node_attr_legend.items()])\n# Create a legend for edge attributes with actual feature names\nedge_feature_names = ['Bond Type', 'Bond Stereo']\nedge_attr_legend = {i: edge_feature_names[i] for i in range(len(edge_feature_names))}\nedge_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in edge_attr_legend.items()])\n# Display the legends\nplt.gcf().text(0.02, 0.5, f\"Node Attributes:\\n{node_attr_legend_text}\", fontsize=10, verticalalignment='center')\nplt.gcf().text(0.98, 0.5, f\"Edge Attributes:\\n{edge_attr_legend_text}\", fontsize=10, verticalalignment='center', horizontalalignment='right')\nplt.title('Graph of a Sample Molecule')",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "node_attr_legend_text",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "node_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in node_attr_legend.items()])\n# Create a legend for edge attributes with actual feature names\nedge_feature_names = ['Bond Type', 'Bond Stereo']\nedge_attr_legend = {i: edge_feature_names[i] for i in range(len(edge_feature_names))}\nedge_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in edge_attr_legend.items()])\n# Display the legends\nplt.gcf().text(0.02, 0.5, f\"Node Attributes:\\n{node_attr_legend_text}\", fontsize=10, verticalalignment='center')\nplt.gcf().text(0.98, 0.5, f\"Edge Attributes:\\n{edge_attr_legend_text}\", fontsize=10, verticalalignment='center', horizontalalignment='right')\nplt.title('Graph of a Sample Molecule')\nplt.show()",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "edge_feature_names",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "edge_feature_names = ['Bond Type', 'Bond Stereo']\nedge_attr_legend = {i: edge_feature_names[i] for i in range(len(edge_feature_names))}\nedge_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in edge_attr_legend.items()])\n# Display the legends\nplt.gcf().text(0.02, 0.5, f\"Node Attributes:\\n{node_attr_legend_text}\", fontsize=10, verticalalignment='center')\nplt.gcf().text(0.98, 0.5, f\"Edge Attributes:\\n{edge_attr_legend_text}\", fontsize=10, verticalalignment='center', horizontalalignment='right')\nplt.title('Graph of a Sample Molecule')\nplt.show()\n# %%",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "edge_attr_legend",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "edge_attr_legend = {i: edge_feature_names[i] for i in range(len(edge_feature_names))}\nedge_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in edge_attr_legend.items()])\n# Display the legends\nplt.gcf().text(0.02, 0.5, f\"Node Attributes:\\n{node_attr_legend_text}\", fontsize=10, verticalalignment='center')\nplt.gcf().text(0.98, 0.5, f\"Edge Attributes:\\n{edge_attr_legend_text}\", fontsize=10, verticalalignment='center', horizontalalignment='right')\nplt.title('Graph of a Sample Molecule')\nplt.show()\n# %%",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "edge_attr_legend_text",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "edge_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in edge_attr_legend.items()])\n# Display the legends\nplt.gcf().text(0.02, 0.5, f\"Node Attributes:\\n{node_attr_legend_text}\", fontsize=10, verticalalignment='center')\nplt.gcf().text(0.98, 0.5, f\"Edge Attributes:\\n{edge_attr_legend_text}\", fontsize=10, verticalalignment='center', horizontalalignment='right')\nplt.title('Graph of a Sample Molecule')\nplt.show()\n# %%",
        "detail": "tox21_analysis",
        "documentation": {}
    }
]