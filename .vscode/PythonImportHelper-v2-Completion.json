[
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "ParameterGrid",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "ParameterGrid",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "ParameterGrid",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "ParameterGrid",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "GradientBoostingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "AdaBoostClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "xgboost",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "xgboost",
        "description": "xgboost",
        "detail": "xgboost",
        "documentation": {}
    },
    {
        "label": "MultiOutputClassifier",
        "importPath": "sklearn.multioutput",
        "description": "sklearn.multioutput",
        "isExtraImport": true,
        "detail": "sklearn.multioutput",
        "documentation": {}
    },
    {
        "label": "precision_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "recall_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "f1_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "balanced_accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "average_precision_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "precision_recall_curve",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "precision_recall_curve",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_curve",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "auc",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "precision_recall_curve",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_curve",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "auc",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "precision_recall_curve",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "precision_recall_curve",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_curve",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "auc",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "preprocessing",
        "description": "preprocessing",
        "detail": "preprocessing",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "GCNTox21",
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "isExtraImport": true,
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "train",
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "isExtraImport": true,
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "validate",
        "importPath": "GCN_node_tox21",
        "description": "GCN_node_tox21",
        "isExtraImport": true,
        "detail": "GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "ReduceLROnPlateau",
        "importPath": "torch.optim.lr_scheduler",
        "description": "torch.optim.lr_scheduler",
        "isExtraImport": true,
        "detail": "torch.optim.lr_scheduler",
        "documentation": {}
    },
    {
        "label": "ReduceLROnPlateau",
        "importPath": "torch.optim.lr_scheduler",
        "description": "torch.optim.lr_scheduler",
        "isExtraImport": true,
        "detail": "torch.optim.lr_scheduler",
        "documentation": {}
    },
    {
        "label": "ReduceLROnPlateau",
        "importPath": "torch.optim.lr_scheduler",
        "description": "torch.optim.lr_scheduler",
        "isExtraImport": true,
        "detail": "torch.optim.lr_scheduler",
        "documentation": {}
    },
    {
        "label": "ReduceLROnPlateau",
        "importPath": "torch.optim.lr_scheduler",
        "description": "torch.optim.lr_scheduler",
        "isExtraImport": true,
        "detail": "torch.optim.lr_scheduler",
        "documentation": {}
    },
    {
        "label": "ReduceLROnPlateau",
        "importPath": "torch.optim.lr_scheduler",
        "description": "torch.optim.lr_scheduler",
        "isExtraImport": true,
        "detail": "torch.optim.lr_scheduler",
        "documentation": {}
    },
    {
        "label": "ReduceLROnPlateau",
        "importPath": "torch.optim.lr_scheduler",
        "description": "torch.optim.lr_scheduler",
        "isExtraImport": true,
        "detail": "torch.optim.lr_scheduler",
        "documentation": {}
    },
    {
        "label": "ReduceLROnPlateau",
        "importPath": "torch.optim.lr_scheduler",
        "description": "torch.optim.lr_scheduler",
        "isExtraImport": true,
        "detail": "torch.optim.lr_scheduler",
        "documentation": {}
    },
    {
        "label": "ReduceLROnPlateau",
        "importPath": "torch.optim.lr_scheduler",
        "description": "torch.optim.lr_scheduler",
        "isExtraImport": true,
        "detail": "torch.optim.lr_scheduler",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.loader",
        "description": "torch_geometric.loader",
        "isExtraImport": true,
        "detail": "torch_geometric.loader",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.loader",
        "description": "torch_geometric.loader",
        "isExtraImport": true,
        "detail": "torch_geometric.loader",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.loader",
        "description": "torch_geometric.loader",
        "isExtraImport": true,
        "detail": "torch_geometric.loader",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.loader",
        "description": "torch_geometric.loader",
        "isExtraImport": true,
        "detail": "torch_geometric.loader",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.loader",
        "description": "torch_geometric.loader",
        "isExtraImport": true,
        "detail": "torch_geometric.loader",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.loader",
        "description": "torch_geometric.loader",
        "isExtraImport": true,
        "detail": "torch_geometric.loader",
        "documentation": {}
    },
    {
        "label": "MoleculeNet",
        "importPath": "torch_geometric.datasets",
        "description": "torch_geometric.datasets",
        "isExtraImport": true,
        "detail": "torch_geometric.datasets",
        "documentation": {}
    },
    {
        "label": "MoleculeNet",
        "importPath": "torch_geometric.datasets",
        "description": "torch_geometric.datasets",
        "isExtraImport": true,
        "detail": "torch_geometric.datasets",
        "documentation": {}
    },
    {
        "label": "MoleculeNet",
        "importPath": "torch_geometric.datasets",
        "description": "torch_geometric.datasets",
        "isExtraImport": true,
        "detail": "torch_geometric.datasets",
        "documentation": {}
    },
    {
        "label": "MoleculeNet",
        "importPath": "torch_geometric.datasets",
        "description": "torch_geometric.datasets",
        "isExtraImport": true,
        "detail": "torch_geometric.datasets",
        "documentation": {}
    },
    {
        "label": "MoleculeNet",
        "importPath": "torch_geometric.datasets",
        "description": "torch_geometric.datasets",
        "isExtraImport": true,
        "detail": "torch_geometric.datasets",
        "documentation": {}
    },
    {
        "label": "MoleculeNet",
        "importPath": "torch_geometric.datasets",
        "description": "torch_geometric.datasets",
        "isExtraImport": true,
        "detail": "torch_geometric.datasets",
        "documentation": {}
    },
    {
        "label": "MoleculeNet",
        "importPath": "torch_geometric.datasets",
        "description": "torch_geometric.datasets",
        "isExtraImport": true,
        "detail": "torch_geometric.datasets",
        "documentation": {}
    },
    {
        "label": "MoleculeNet",
        "importPath": "torch_geometric.datasets",
        "description": "torch_geometric.datasets",
        "isExtraImport": true,
        "detail": "torch_geometric.datasets",
        "documentation": {}
    },
    {
        "label": "MoleculeNet",
        "importPath": "torch_geometric.datasets",
        "description": "torch_geometric.datasets",
        "isExtraImport": true,
        "detail": "torch_geometric.datasets",
        "documentation": {}
    },
    {
        "label": "GCNTox21",
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "isExtraImport": true,
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "train",
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "isExtraImport": true,
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "validate",
        "importPath": "GCN_tox21",
        "description": "GCN_tox21",
        "isExtraImport": true,
        "detail": "GCN_tox21",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "GCNTox21NNConv",
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "isExtraImport": true,
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "train",
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "isExtraImport": true,
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "validate",
        "importPath": "NNConv_tox21",
        "description": "NNConv_tox21",
        "isExtraImport": true,
        "detail": "NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "GATTox21",
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "isExtraImport": true,
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "train",
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "isExtraImport": true,
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "validate",
        "importPath": "GAT_tox21",
        "description": "GAT_tox21",
        "isExtraImport": true,
        "detail": "GAT_tox21",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "GATv2Conv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "global_mean_pool",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "EdgeConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "GCNConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "global_mean_pool",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "EdgeConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "GCNConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "global_mean_pool",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "EdgeConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "MessagePassing",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "GCNConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "global_mean_pool",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "EdgeConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "NNConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "torch.utils.tensorboard",
        "description": "torch.utils.tensorboard",
        "isExtraImport": true,
        "detail": "torch.utils.tensorboard",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "torch.utils.tensorboard",
        "description": "torch.utils.tensorboard",
        "isExtraImport": true,
        "detail": "torch.utils.tensorboard",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "torch.utils.tensorboard",
        "description": "torch.utils.tensorboard",
        "isExtraImport": true,
        "detail": "torch.utils.tensorboard",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "torch.utils.tensorboard",
        "description": "torch.utils.tensorboard",
        "isExtraImport": true,
        "detail": "torch.utils.tensorboard",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "Chem",
        "importPath": "rdkit",
        "description": "rdkit",
        "isExtraImport": true,
        "detail": "rdkit",
        "documentation": {}
    },
    {
        "label": "Draw",
        "importPath": "rdkit.Chem",
        "description": "rdkit.Chem",
        "isExtraImport": true,
        "detail": "rdkit.Chem",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "display",
        "importPath": "IPython.display",
        "description": "IPython.display",
        "isExtraImport": true,
        "detail": "IPython.display",
        "documentation": {}
    },
    {
        "label": "networkx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "networkx",
        "description": "networkx",
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "to_networkx",
        "importPath": "torch_geometric.utils",
        "description": "torch_geometric.utils",
        "isExtraImport": true,
        "detail": "torch_geometric.utils",
        "documentation": {}
    },
    {
        "label": "tabulate",
        "importPath": "tabulate",
        "description": "tabulate",
        "isExtraImport": true,
        "detail": "tabulate",
        "documentation": {}
    },
    {
        "label": "CreateSymbolDataset",
        "kind": 6,
        "importPath": "Baseline.preprocessing",
        "description": "Baseline.preprocessing",
        "peekOfCode": "class CreateSymbolDataset(object):\n    \"\"\"\n    Base class responsibe for enumerating symbols (atoms) with the smile.\n    \"\"\"\n    def __init__(self, smiles):\n        self.smiles = smiles\n        self.max_size = self._get_max_size()\n        self.N = len(self.smiles)\n    def _get_max_size(self)->int:\n        \"\"\"",
        "detail": "Baseline.preprocessing",
        "documentation": {}
    },
    {
        "label": "BagOfWords",
        "kind": 6,
        "importPath": "Baseline.preprocessing",
        "description": "Baseline.preprocessing",
        "peekOfCode": "class BagOfWords(CreateSymbolDataset):\n    \"\"\"\n    Class responsible for creating a bag of words-like dataset based off by treating the characters of the smiles as individual symbols - thus,\n    this does not consider atoms in the chemistry sense.\n    Basic usage:\n    >> smiles = X_train_source['SMILES'].values\n    >> bow = pp.BagOfWords(smiles)\n    >> bow_train = bow.fit()\n    >> bow_test = bow.transform(X_test_source['SMILES'].values)\n    \"\"\"",
        "detail": "Baseline.preprocessing",
        "documentation": {}
    },
    {
        "label": "BagOfWordsMols",
        "kind": 6,
        "importPath": "Baseline.preprocessing",
        "description": "Baseline.preprocessing",
        "peekOfCode": "class BagOfWordsMols(CreateSymbolDataset):\n    \"\"\"\n    Class responsible for creating a bag of words-like dataset based off by symbols which are understood to be atoms by making use of the _split function.\n    Basic usage:\n    >> smiles = X_train_source['SMILES'].values\n    >> bow = pp.BagOfWordsMols(smiles)\n    >> bow_train = bow.fit()\n    >> bow_test = bow.transform(X_test_source['SMILES'].values)\n    \"\"\"\n    def __init__(self, smiles:list):",
        "detail": "Baseline.preprocessing",
        "documentation": {}
    },
    {
        "label": "MorganFingerprints",
        "kind": 6,
        "importPath": "Baseline.preprocessing",
        "description": "Baseline.preprocessing",
        "peekOfCode": "class MorganFingerprints(CreateSymbolDataset):\n    \"\"\"\n    Class that finds the morgan fingerprint for the smiles.\n    Basic usage:\n    >> smiles = data['SMILES'].values\n    >> mf = MorganFingerprints(smiles)\n    >> X = mf.transform(radius)\n    \"\"\"\n    def __init__(self, smiles:list):\n        super(MorganFingerprints, self).__init__(smiles)",
        "detail": "Baseline.preprocessing",
        "documentation": {}
    },
    {
        "label": "MurckoScaffold",
        "kind": 6,
        "importPath": "Baseline.preprocessing",
        "description": "Baseline.preprocessing",
        "peekOfCode": "class MurckoScaffold(CreateSymbolDataset):\n    \"\"\"\n    This class finds the scaffolding for a given smiles, and applies it to a list of smiles - it is essentially a wrapper around the core\n    functionality of rdkit.\n    Basic usage:\n    >> smiles = data['SMILES'].values\n    >> ms = pp.MurckoScaffold(smiles)\n    >> X = ms.transform()\n    \"\"\"\n    def __init__(self, smiles:list):",
        "detail": "Baseline.preprocessing",
        "documentation": {}
    },
    {
        "label": "MolecularDescriptors",
        "kind": 6,
        "importPath": "Baseline.preprocessing",
        "description": "Baseline.preprocessing",
        "peekOfCode": "class MolecularDescriptors:\n    \"\"\"\n    Class responsible for find the molecular descriptors of the smiles.\n    Basic usage:\n    >> mol = Chem.MolFromSmiles(smile) \n    >> moldes = pp.MolecularDescriptors(mol)\n    >> res = moldes.compute_all(mol)\n    \"\"\"\n    def __init__(self, smiles:list):\n        self.smiles = smiles",
        "detail": "Baseline.preprocessing",
        "documentation": {}
    },
    {
        "label": "VectorRepresentation",
        "kind": 6,
        "importPath": "Baseline.preprocessing",
        "description": "Baseline.preprocessing",
        "peekOfCode": "class VectorRepresentation(CreateSymbolDataset):\n    def __init__(self,smiles):\n        super(VectorRepresentation, self).__init__(smiles)\n    def fit(self, max_len = None):\n        self._get_list_symbols()\n        self.symbols.append('_unk_')\n        self.sym_idx['_unk_'] = len(self.symbols)-1\n        self.symbols.append('_pad_')\n        self.sym_idx['_pad_'] = len(self.symbols)-1\n        if max_len is None or max_len < self.max_size:",
        "detail": "Baseline.preprocessing",
        "documentation": {}
    },
    {
        "label": "VectorRepresentationMols",
        "kind": 6,
        "importPath": "Baseline.preprocessing",
        "description": "Baseline.preprocessing",
        "peekOfCode": "class VectorRepresentationMols(CreateSymbolDataset):\n    def __init__(self,smiles):\n        super(VectorRepresentationMols, self).__init__(smiles)\n        self.smiles = self._isolate_mols_from_smiles(smiles)\n    def _isolate_mols_from_smiles(self, smiles):\n        smiles = np.array([_split(smi) for smi in smiles])\n        return smiles\n    def fit(self, max_len = None):\n        self._get_list_symbols(' ')\n        self.symbols.append('_unk_')",
        "detail": "Baseline.preprocessing",
        "documentation": {}
    },
    {
        "label": "all_descriptors",
        "kind": 5,
        "importPath": "Baseline.preprocessing",
        "description": "Baseline.preprocessing",
        "peekOfCode": "all_descriptors = ['Asphericity',\n 'Eccentricity',\n 'InertialShapeFactor',\n 'NPR1',\n 'NPR2',\n 'PMI1',\n 'PMI2',\n 'PMI3',\n 'RadiusOfGyration',\n 'SpherocityIndex',",
        "detail": "Baseline.preprocessing",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": "Baseline.tox21-baseline",
        "description": "Baseline.tox21-baseline",
        "peekOfCode": "def load_and_prepare_data(data_path: str) -> Tuple[pd.DataFrame, pd.DataFrame, List[str], List[str]]:\n    \"\"\"\n    Load and prepare the Tox21 dataset for modeling.\n    \"\"\"\n    data = pd.read_csv(data_path, index_col=0)\n    features = ['FW', 'SMILES']\n    targets = ['SR-HSE','NR-AR', 'SR-ARE', 'NR-Aromatase', 'NR-ER-LBD', 'NR-AhR', 'SR-MMP',\\\n       'NR-ER', 'NR-PPAR-gamma', 'SR-p53', 'SR-ATAD5', 'NR-AR-LBD']\n    X = data[features]\n    y = data[targets]",
        "detail": "Baseline.tox21-baseline",
        "documentation": {}
    },
    {
        "label": "preprocess_data",
        "kind": 2,
        "importPath": "Baseline.tox21-baseline",
        "description": "Baseline.tox21-baseline",
        "peekOfCode": "def preprocess_data(X: pd.DataFrame, y: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n    \"\"\"\n    Preprocess the data by handling missing values and creating masks.\n    \"\"\"\n    features_types = {'FW': float, 'SMILES': object}\n    target_types = {n: float for n in y.columns}\n    X = X.astype(features_types)\n    y = y.astype(target_types)\n    null_mask = np.array(np.logical_not(y.isnull().values), int)\n    y = y.fillna(0.0)",
        "detail": "Baseline.tox21-baseline",
        "documentation": {}
    },
    {
        "label": "create_train_test_split",
        "kind": 2,
        "importPath": "Baseline.tox21-baseline",
        "description": "Baseline.tox21-baseline",
        "peekOfCode": "def create_train_test_split(X: pd.DataFrame, y: pd.DataFrame, mask_df: pd.DataFrame, \n                          test_size: float = 0.2, random_state: int = 42) -> Tuple:\n    \"\"\"\n    Split the data into training and test sets.\n    \"\"\"\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=test_size, random_state=random_state\n    )\n    target_cols = y.columns[:len(mask_df.columns)]\n    y_train, mask_train = y_train[target_cols], y_train[mask_df.columns]",
        "detail": "Baseline.tox21-baseline",
        "documentation": {}
    },
    {
        "label": "generate_features",
        "kind": 2,
        "importPath": "Baseline.tox21-baseline",
        "description": "Baseline.tox21-baseline",
        "peekOfCode": "def generate_features(X_train: pd.DataFrame, X_test: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Generate features from SMILES strings using bag-of-words encoding.\n    \"\"\"\n    bow = pp.BagOfWords(X_train['SMILES'].values)\n    bow_train = bow.fit()\n    bow_test = bow.transform(X_test['SMILES'].values)\n    bow_train = np.insert(bow_train, 0, X_train['FW'], 1)\n    bow_test = np.insert(bow_test, 0, X_test['FW'], 1)\n    scaler = StandardScaler()",
        "detail": "Baseline.tox21-baseline",
        "documentation": {}
    },
    {
        "label": "initialize_model",
        "kind": 2,
        "importPath": "Baseline.tox21-baseline",
        "description": "Baseline.tox21-baseline",
        "peekOfCode": "def initialize_model(model_name: str) -> Any:\n    \"\"\"\n    Initialize a model based on the configuration.\n    \"\"\"\n    config = MODEL_CONFIGS[model_name]\n    if 'base' in config:\n        base_model = config['base'](**config['params'])\n        return config['class'](base_model)\n    else:\n        return config['class'](**config['params'])",
        "detail": "Baseline.tox21-baseline",
        "documentation": {}
    },
    {
        "label": "train_model",
        "kind": 2,
        "importPath": "Baseline.tox21-baseline",
        "description": "Baseline.tox21-baseline",
        "peekOfCode": "def train_model(model: Any, X_train: np.ndarray, y_train: np.ndarray, \n                model_path: Optional[str] = None) -> Any:\n    \"\"\"\n    Train a model and optionally save it.\n    \"\"\"\n    model.fit(X_train, y_train)\n    if model_path:\n        with open(model_path, 'wb') as f:\n            pickle.dump(model, f)\n    return model",
        "detail": "Baseline.tox21-baseline",
        "documentation": {}
    },
    {
        "label": "get_predictions_and_scores",
        "kind": 2,
        "importPath": "Baseline.tox21-baseline",
        "description": "Baseline.tox21-baseline",
        "peekOfCode": "def get_predictions_and_scores(model: Any, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Get predictions and probability scores from the model.\n    \"\"\"\n    if isinstance(model, MultiOutputClassifier):\n        y_pred = model.predict(X)\n        y_score = np.array([estimator.predict_proba(X)[:, 1] \n                           for estimator in model.estimators_]).T\n    else:\n        y_pred = model.predict(X)",
        "detail": "Baseline.tox21-baseline",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": "Baseline.tox21-baseline",
        "description": "Baseline.tox21-baseline",
        "peekOfCode": "def calculate_metrics(y_true: np.ndarray, y_pred: np.ndarray, \n                     y_score: np.ndarray, sample_weights: Optional[np.ndarray] = None) -> Dict:\n    \"\"\"\n    Calculate metrics for binary classification.\n    \"\"\"\n    metrics = {}\n    # Basic classification metrics\n    metrics['precision'] = precision_score(y_true, y_pred, sample_weight=sample_weights)\n    metrics['recall'] = recall_score(y_true, y_pred, sample_weight=sample_weights)\n    metrics['f1'] = f1_score(y_true, y_pred, sample_weight=sample_weights)",
        "detail": "Baseline.tox21-baseline",
        "documentation": {}
    },
    {
        "label": "evaluate_model_performance",
        "kind": 2,
        "importPath": "Baseline.tox21-baseline",
        "description": "Baseline.tox21-baseline",
        "peekOfCode": "def evaluate_model_performance(model: Any, X: np.ndarray, y: np.ndarray, \n                             targets: List[str], sample_weights: Optional[np.ndarray] = None) -> pd.DataFrame:\n    \"\"\"\n    Evaluate model performance across all targets.\n    \"\"\"\n    # Get predictions and scores\n    y_pred, y_score = get_predictions_and_scores(model, X)\n    # Calculate metrics for each target\n    all_metrics = []\n    for i, target in enumerate(targets):",
        "detail": "Baseline.tox21-baseline",
        "documentation": {}
    },
    {
        "label": "plot_confusion_matrices",
        "kind": 2,
        "importPath": "Baseline.tox21-baseline",
        "description": "Baseline.tox21-baseline",
        "peekOfCode": "def plot_confusion_matrices(y_true: np.ndarray, y_pred: np.ndarray, \n                          targets: List[str], output_path: str) -> None:\n    \"\"\"\n    Plot confusion matrices for all targets.\n    \"\"\"\n    n_targets = len(targets)\n    fig, axes = plt.subplots(4, 3, figsize=(15, 10))\n    axes = axes.ravel()\n    for i, target in enumerate(targets):\n        cm = confusion_matrix(y_true[:, i], y_pred[:, i])",
        "detail": "Baseline.tox21-baseline",
        "documentation": {}
    },
    {
        "label": "plot_precision_recall_curves",
        "kind": 2,
        "importPath": "Baseline.tox21-baseline",
        "description": "Baseline.tox21-baseline",
        "peekOfCode": "def plot_precision_recall_curves(y_true: np.ndarray, y_score: np.ndarray, \n                               targets: List[str], output_path: str) -> None:\n    \"\"\"\n    Plot precision-recall curves for all targets.\n    \"\"\"\n    plt.figure(figsize=(10, 6))\n    for i, target in enumerate(targets):\n        precision, recall, _ = precision_recall_curve(y_true[:, i], y_score[:, i])\n        ap = average_precision_score(y_true[:, i], y_score[:, i])\n        plt.plot(recall, precision, label=f'{target} (AP={ap:.2f})')",
        "detail": "Baseline.tox21-baseline",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "Baseline.tox21-baseline",
        "description": "Baseline.tox21-baseline",
        "peekOfCode": "def main():\n    # Configuration\n    DATA_PATH = 'data/data.csv'\n    OUTPUT_DIR = Path('output')\n    MODELS_DIR = OUTPUT_DIR / 'models'\n    METRICS_DIR = OUTPUT_DIR / 'metrics'\n    PLOTS_DIR = OUTPUT_DIR / 'plots'\n    # Create output directories\n    for dir_path in [MODELS_DIR, METRICS_DIR, PLOTS_DIR]:\n        dir_path.mkdir(parents=True, exist_ok=True)",
        "detail": "Baseline.tox21-baseline",
        "documentation": {}
    },
    {
        "label": "MODEL_CONFIGS",
        "kind": 5,
        "importPath": "Baseline.tox21-baseline",
        "description": "Baseline.tox21-baseline",
        "peekOfCode": "MODEL_CONFIGS = {\n    'random_forest': {\n        'class': RandomForestClassifier,\n        'params': {\n            'n_estimators': 100,\n            'max_depth': 10,\n            'random_state': 42\n        }\n    },\n    'xgboost': {",
        "detail": "Baseline.tox21-baseline",
        "documentation": {}
    },
    {
        "label": "run_grid_search",
        "kind": 2,
        "importPath": "grid search.grid_search_GCN_node_tox21",
        "description": "grid search.grid_search_GCN_node_tox21",
        "peekOfCode": "def run_grid_search(grid, search_name):\n    global best_params, best_val_auc\n    best_metrics = None\n    for params in grid:\n        print(f\"Testing combination ({search_name}): {params}\")\n        # Determine if we are using grid_1 or grid_2 parameters\n        if search_name == \"Grid 1\":  # These are the learning rate scheduler parameters\n            # Initialize model with default parameters for the architecture\n            model = GCNTox21(\n                num_node_features=dataset[0].num_node_features,",
        "detail": "grid search.grid_search_GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "param_grid_1",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_node_tox21",
        "description": "grid search.grid_search_GCN_node_tox21",
        "peekOfCode": "param_grid_1 = {\n    'lr': [1e-4, 1e-3],\n    'factor': [0.1, 0.5],\n    'patience': [2, 5, 10],\n    'threshold': [1e-4, 1e-3],\n    'min_lr': [1e-6, 1e-5],\n}\nparam_grid_2 = {\n    'hidden_dim': [64, 128, 256],\n    'num_layers': [3, 4, 5],",
        "detail": "grid search.grid_search_GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "param_grid_2",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_node_tox21",
        "description": "grid search.grid_search_GCN_node_tox21",
        "peekOfCode": "param_grid_2 = {\n    'hidden_dim': [64, 128, 256],\n    'num_layers': [3, 4, 5],\n    'dropout': [0.2, 0.3, 0.5]\n}\n# Setup and training\ndataset = MoleculeNet(root='data/TOX21', name='TOX21')\ntrain_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)",
        "detail": "grid search.grid_search_GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "dataset",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_node_tox21",
        "description": "grid search.grid_search_GCN_node_tox21",
        "peekOfCode": "dataset = MoleculeNet(root='data/TOX21', name='TOX21')\ntrain_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0",
        "detail": "grid search.grid_search_GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "train_dataset",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_node_tox21",
        "description": "grid search.grid_search_GCN_node_tox21",
        "peekOfCode": "train_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
        "detail": "grid search.grid_search_GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "test_dataset",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_node_tox21",
        "description": "grid search.grid_search_GCN_node_tox21",
        "peekOfCode": "test_dataset = dataset[int(0.8 * len(dataset)):]\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run grid search for both grids",
        "detail": "grid search.grid_search_GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "train_loader",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_node_tox21",
        "description": "grid search.grid_search_GCN_node_tox21",
        "peekOfCode": "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run grid search for both grids\ndef run_grid_search(grid, search_name):",
        "detail": "grid search.grid_search_GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "test_loader",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_node_tox21",
        "description": "grid search.grid_search_GCN_node_tox21",
        "peekOfCode": "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run grid search for both grids\ndef run_grid_search(grid, search_name):\n    global best_params, best_val_auc",
        "detail": "grid search.grid_search_GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "grid_1",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_node_tox21",
        "description": "grid search.grid_search_GCN_node_tox21",
        "peekOfCode": "grid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run grid search for both grids\ndef run_grid_search(grid, search_name):\n    global best_params, best_val_auc\n    best_metrics = None\n    for params in grid:",
        "detail": "grid search.grid_search_GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "grid_2",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_node_tox21",
        "description": "grid search.grid_search_GCN_node_tox21",
        "peekOfCode": "grid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run grid search for both grids\ndef run_grid_search(grid, search_name):\n    global best_params, best_val_auc\n    best_metrics = None\n    for params in grid:\n        print(f\"Testing combination ({search_name}): {params}\")",
        "detail": "grid search.grid_search_GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "best_val_auc",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_node_tox21",
        "description": "grid search.grid_search_GCN_node_tox21",
        "peekOfCode": "best_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run grid search for both grids\ndef run_grid_search(grid, search_name):\n    global best_params, best_val_auc\n    best_metrics = None\n    for params in grid:\n        print(f\"Testing combination ({search_name}): {params}\")\n        # Determine if we are using grid_1 or grid_2 parameters\n        if search_name == \"Grid 1\":  # These are the learning rate scheduler parameters",
        "detail": "grid search.grid_search_GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_node_tox21",
        "description": "grid search.grid_search_GCN_node_tox21",
        "peekOfCode": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run grid search for both grids\ndef run_grid_search(grid, search_name):\n    global best_params, best_val_auc\n    best_metrics = None\n    for params in grid:\n        print(f\"Testing combination ({search_name}): {params}\")\n        # Determine if we are using grid_1 or grid_2 parameters\n        if search_name == \"Grid 1\":  # These are the learning rate scheduler parameters\n            # Initialize model with default parameters for the architecture",
        "detail": "grid search.grid_search_GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_node_tox21",
        "description": "grid search.grid_search_GCN_node_tox21",
        "peekOfCode": "results = {\n    'best_config_lr': best_params_1,\n    'best_metrics_lr': best_metrics_1,\n    'best_config_architecture': best_params_2,\n    'best_metrics_architecture': best_metrics_2\n}\nwith open('grid_search/grid_search_GCN_node_results.json', 'w') as f:\n    json.dump(results, f, indent=4)\nprint(\"Best configuration and metrics saved to grid_search_results.json.\")",
        "detail": "grid search.grid_search_GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "run_grid_search",
        "kind": 2,
        "importPath": "grid search.grid_search_GCN_tox21",
        "description": "grid search.grid_search_GCN_tox21",
        "peekOfCode": "def run_grid_search(grid, search_name):\n    global best_params, best_val_auc\n    best_metrics = None\n    for params in grid:\n        print(f\"Testing combination ({search_name}): {params}\")\n        if search_name == \"Grid 1\":  # Learning rate scheduler parameters\n            # Default model parameters for grid_1 search\n            model = GCNTox21(\n                num_node_features=dataset[0].num_node_features,\n                num_edge_features=dataset[0].num_edge_features,",
        "detail": "grid search.grid_search_GCN_tox21",
        "documentation": {}
    },
    {
        "label": "param_grid_1",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_tox21",
        "description": "grid search.grid_search_GCN_tox21",
        "peekOfCode": "param_grid_1 = {\n    'lr': [1e-4, 1e-3],\n    'factor': [0.1, 0.5],\n    'patience': [2, 5, 10],\n}\nparam_grid_2 = {\n    'hidden_dim': [64, 128, 256],\n    'num_layers': [3, 4, 5],\n    'edge_hidden': [16, 32, 64],\n    'dropout': [0.2, 0.3, 0.5]",
        "detail": "grid search.grid_search_GCN_tox21",
        "documentation": {}
    },
    {
        "label": "param_grid_2",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_tox21",
        "description": "grid search.grid_search_GCN_tox21",
        "peekOfCode": "param_grid_2 = {\n    'hidden_dim': [64, 128, 256],\n    'num_layers': [3, 4, 5],\n    'edge_hidden': [16, 32, 64],\n    'dropout': [0.2, 0.3, 0.5]\n}\n# Setup and training\ndataset = MoleculeNet(root='data/TOX21', name='TOX21')\ntrain_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]",
        "detail": "grid search.grid_search_GCN_tox21",
        "documentation": {}
    },
    {
        "label": "dataset",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_tox21",
        "description": "grid search.grid_search_GCN_tox21",
        "peekOfCode": "dataset = MoleculeNet(root='data/TOX21', name='TOX21')\ntrain_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0",
        "detail": "grid search.grid_search_GCN_tox21",
        "documentation": {}
    },
    {
        "label": "train_dataset",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_tox21",
        "description": "grid search.grid_search_GCN_tox21",
        "peekOfCode": "train_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
        "detail": "grid search.grid_search_GCN_tox21",
        "documentation": {}
    },
    {
        "label": "test_dataset",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_tox21",
        "description": "grid search.grid_search_GCN_tox21",
        "peekOfCode": "test_dataset = dataset[int(0.8 * len(dataset)):]\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids",
        "detail": "grid search.grid_search_GCN_tox21",
        "documentation": {}
    },
    {
        "label": "train_loader",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_tox21",
        "description": "grid search.grid_search_GCN_tox21",
        "peekOfCode": "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):",
        "detail": "grid search.grid_search_GCN_tox21",
        "documentation": {}
    },
    {
        "label": "test_loader",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_tox21",
        "description": "grid search.grid_search_GCN_tox21",
        "peekOfCode": "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):\n    global best_params, best_val_auc",
        "detail": "grid search.grid_search_GCN_tox21",
        "documentation": {}
    },
    {
        "label": "grid_1",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_tox21",
        "description": "grid search.grid_search_GCN_tox21",
        "peekOfCode": "grid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):\n    global best_params, best_val_auc\n    best_metrics = None\n    for params in grid:",
        "detail": "grid search.grid_search_GCN_tox21",
        "documentation": {}
    },
    {
        "label": "grid_2",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_tox21",
        "description": "grid search.grid_search_GCN_tox21",
        "peekOfCode": "grid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):\n    global best_params, best_val_auc\n    best_metrics = None\n    for params in grid:\n        print(f\"Testing combination ({search_name}): {params}\")",
        "detail": "grid search.grid_search_GCN_tox21",
        "documentation": {}
    },
    {
        "label": "best_val_auc",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_tox21",
        "description": "grid search.grid_search_GCN_tox21",
        "peekOfCode": "best_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):\n    global best_params, best_val_auc\n    best_metrics = None\n    for params in grid:\n        print(f\"Testing combination ({search_name}): {params}\")\n        if search_name == \"Grid 1\":  # Learning rate scheduler parameters\n            # Default model parameters for grid_1 search",
        "detail": "grid search.grid_search_GCN_tox21",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_tox21",
        "description": "grid search.grid_search_GCN_tox21",
        "peekOfCode": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):\n    global best_params, best_val_auc\n    best_metrics = None\n    for params in grid:\n        print(f\"Testing combination ({search_name}): {params}\")\n        if search_name == \"Grid 1\":  # Learning rate scheduler parameters\n            # Default model parameters for grid_1 search\n            model = GCNTox21(",
        "detail": "grid search.grid_search_GCN_tox21",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": "grid search.grid_search_GCN_tox21",
        "description": "grid search.grid_search_GCN_tox21",
        "peekOfCode": "results = {\n    'best_config_lr': best_params_1,\n    'best_metrics_lr': best_metrics_1,\n    'best_config_architecture': best_params_2,\n    'best_metrics_architecture': best_metrics_2\n}\nwith open('grid_search/grid_search_GCN_results.json', 'w') as f:\n    json.dump(results, f, indent=4)\nprint(\"Best configuration and metrics saved to grid_search_results.json.\")",
        "detail": "grid search.grid_search_GCN_tox21",
        "documentation": {}
    },
    {
        "label": "run_grid_search",
        "kind": 2,
        "importPath": "grid search.grid_search_NNConv_tox21",
        "description": "grid search.grid_search_NNConv_tox21",
        "peekOfCode": "def run_grid_search(grid, search_name):\n    best_params = None  \n    best_val_auc = 0 \n    best_metrics = None\n    for params in grid:\n        print(f\"Testing combination ({search_name}): {params}\")\n        if search_name == \"Grid 1\":  # Learning rate scheduler parameters\n            # Default model parameters for grid_1 search\n            model = GCNTox21NNConv(\n                dataset[0].num_node_features,",
        "detail": "grid search.grid_search_NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "param_grid_1",
        "kind": 5,
        "importPath": "grid search.grid_search_NNConv_tox21",
        "description": "grid search.grid_search_NNConv_tox21",
        "peekOfCode": "param_grid_1 = {\n    'lr': [1e-4, 1e-3],\n    'factor': [0.1, 0.5],\n    'patience': [2, 5, 10],\n}\nparam_grid_2 = {\n    'hidden_dim': [64, 128, 256],\n    'num_heads': [2, 4, 8],\n    'num_layers': [3, 4, 5],\n    'dropout': [0.2, 0.3, 0.5]",
        "detail": "grid search.grid_search_NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "param_grid_2",
        "kind": 5,
        "importPath": "grid search.grid_search_NNConv_tox21",
        "description": "grid search.grid_search_NNConv_tox21",
        "peekOfCode": "param_grid_2 = {\n    'hidden_dim': [64, 128, 256],\n    'num_heads': [2, 4, 8],\n    'num_layers': [3, 4, 5],\n    'dropout': [0.2, 0.3, 0.5]\n}\n# Setup and training\ndataset = MoleculeNet(root='data/TOX21', name='TOX21')\ntrain_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]",
        "detail": "grid search.grid_search_NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "dataset",
        "kind": 5,
        "importPath": "grid search.grid_search_NNConv_tox21",
        "description": "grid search.grid_search_NNConv_tox21",
        "peekOfCode": "dataset = MoleculeNet(root='data/TOX21', name='TOX21')\ntrain_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0",
        "detail": "grid search.grid_search_NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "train_dataset",
        "kind": 5,
        "importPath": "grid search.grid_search_NNConv_tox21",
        "description": "grid search.grid_search_NNConv_tox21",
        "peekOfCode": "train_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
        "detail": "grid search.grid_search_NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "test_dataset",
        "kind": 5,
        "importPath": "grid search.grid_search_NNConv_tox21",
        "description": "grid search.grid_search_NNConv_tox21",
        "peekOfCode": "test_dataset = dataset[int(0.8 * len(dataset)):]\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids",
        "detail": "grid search.grid_search_NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "train_loader",
        "kind": 5,
        "importPath": "grid search.grid_search_NNConv_tox21",
        "description": "grid search.grid_search_NNConv_tox21",
        "peekOfCode": "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):",
        "detail": "grid search.grid_search_NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "test_loader",
        "kind": 5,
        "importPath": "grid search.grid_search_NNConv_tox21",
        "description": "grid search.grid_search_NNConv_tox21",
        "peekOfCode": "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):\n    best_params = None  ",
        "detail": "grid search.grid_search_NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "grid_1",
        "kind": 5,
        "importPath": "grid search.grid_search_NNConv_tox21",
        "description": "grid search.grid_search_NNConv_tox21",
        "peekOfCode": "grid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):\n    best_params = None  \n    best_val_auc = 0 \n    best_metrics = None",
        "detail": "grid search.grid_search_NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "grid_2",
        "kind": 5,
        "importPath": "grid search.grid_search_NNConv_tox21",
        "description": "grid search.grid_search_NNConv_tox21",
        "peekOfCode": "grid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):\n    best_params = None  \n    best_val_auc = 0 \n    best_metrics = None\n    for params in grid:",
        "detail": "grid search.grid_search_NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "best_val_auc",
        "kind": 5,
        "importPath": "grid search.grid_search_NNConv_tox21",
        "description": "grid search.grid_search_NNConv_tox21",
        "peekOfCode": "best_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):\n    best_params = None  \n    best_val_auc = 0 \n    best_metrics = None\n    for params in grid:\n        print(f\"Testing combination ({search_name}): {params}\")\n        if search_name == \"Grid 1\":  # Learning rate scheduler parameters",
        "detail": "grid search.grid_search_NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "grid search.grid_search_NNConv_tox21",
        "description": "grid search.grid_search_NNConv_tox21",
        "peekOfCode": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):\n    best_params = None  \n    best_val_auc = 0 \n    best_metrics = None\n    for params in grid:\n        print(f\"Testing combination ({search_name}): {params}\")\n        if search_name == \"Grid 1\":  # Learning rate scheduler parameters\n            # Default model parameters for grid_1 search",
        "detail": "grid search.grid_search_NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": "grid search.grid_search_NNConv_tox21",
        "description": "grid search.grid_search_NNConv_tox21",
        "peekOfCode": "results = {\n    'best_config_lr': best_params_1,\n    'best_metrics_lr': best_metrics_1,\n    'best_config_architecture': best_params_2,\n    'best_metrics_architecture': best_metrics_2\n}\nwith open('grid_search/grid_search_NNConv_results.json', 'w') as f:\n    json.dump(results, f, indent=4)\nprint(\"Best configuration and metrics saved to grid_search_NNConv_results.json.\")",
        "detail": "grid search.grid_search_NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "run_grid_search",
        "kind": 2,
        "importPath": "grid search.grid_serch_GAT_tox_21",
        "description": "grid search.grid_serch_GAT_tox_21",
        "peekOfCode": "def run_grid_search(grid, search_name):\n    best_params = None  \n    best_val_auc = 0 \n    best_metrics = None\n    for params in grid:\n        print(f\"Testing combination ({search_name}): {params}\")\n        if search_name == \"Grid 1\":  # Learning rate scheduler parameters\n            # Default model parameters for grid_1 search\n            model = GATTox21(\n                dataset[0].num_node_features,",
        "detail": "grid search.grid_serch_GAT_tox_21",
        "documentation": {}
    },
    {
        "label": "param_grid_1",
        "kind": 5,
        "importPath": "grid search.grid_serch_GAT_tox_21",
        "description": "grid search.grid_serch_GAT_tox_21",
        "peekOfCode": "param_grid_1 = {\n    'lr': [1e-4, 1e-3],\n    'factor': [0.1, 0.5],\n    'patience': [2, 5, 10],\n}\nparam_grid_2 = {\n    'hidden_dim': [64, 128, 256],\n    'num_heads': [2, 4, 8],\n    'num_layers': [3, 4, 5],\n    'dropout': [0.2, 0.3, 0.5]",
        "detail": "grid search.grid_serch_GAT_tox_21",
        "documentation": {}
    },
    {
        "label": "param_grid_2",
        "kind": 5,
        "importPath": "grid search.grid_serch_GAT_tox_21",
        "description": "grid search.grid_serch_GAT_tox_21",
        "peekOfCode": "param_grid_2 = {\n    'hidden_dim': [64, 128, 256],\n    'num_heads': [2, 4, 8],\n    'num_layers': [3, 4, 5],\n    'dropout': [0.2, 0.3, 0.5]\n}\n# Setup and training\ndataset = MoleculeNet(root='data/TOX21', name='TOX21')\ntrain_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]",
        "detail": "grid search.grid_serch_GAT_tox_21",
        "documentation": {}
    },
    {
        "label": "dataset",
        "kind": 5,
        "importPath": "grid search.grid_serch_GAT_tox_21",
        "description": "grid search.grid_serch_GAT_tox_21",
        "peekOfCode": "dataset = MoleculeNet(root='data/TOX21', name='TOX21')\ntrain_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0",
        "detail": "grid search.grid_serch_GAT_tox_21",
        "documentation": {}
    },
    {
        "label": "train_dataset",
        "kind": 5,
        "importPath": "grid search.grid_serch_GAT_tox_21",
        "description": "grid search.grid_serch_GAT_tox_21",
        "peekOfCode": "train_dataset = dataset[:int(0.8 * len(dataset))]\ntest_dataset = dataset[int(0.8 * len(dataset)):]\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
        "detail": "grid search.grid_serch_GAT_tox_21",
        "documentation": {}
    },
    {
        "label": "test_dataset",
        "kind": 5,
        "importPath": "grid search.grid_serch_GAT_tox_21",
        "description": "grid search.grid_serch_GAT_tox_21",
        "peekOfCode": "test_dataset = dataset[int(0.8 * len(dataset)):]\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids",
        "detail": "grid search.grid_serch_GAT_tox_21",
        "documentation": {}
    },
    {
        "label": "train_loader",
        "kind": 5,
        "importPath": "grid search.grid_serch_GAT_tox_21",
        "description": "grid search.grid_serch_GAT_tox_21",
        "peekOfCode": "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):",
        "detail": "grid search.grid_serch_GAT_tox_21",
        "documentation": {}
    },
    {
        "label": "test_loader",
        "kind": 5,
        "importPath": "grid search.grid_serch_GAT_tox_21",
        "description": "grid search.grid_serch_GAT_tox_21",
        "peekOfCode": "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n# Generate all parameter combinations for both grid_1 and grid_2\ngrid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):\n    best_params = None  ",
        "detail": "grid search.grid_serch_GAT_tox_21",
        "documentation": {}
    },
    {
        "label": "grid_1",
        "kind": 5,
        "importPath": "grid search.grid_serch_GAT_tox_21",
        "description": "grid search.grid_serch_GAT_tox_21",
        "peekOfCode": "grid_1 = ParameterGrid(param_grid_1)\ngrid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):\n    best_params = None  \n    best_val_auc = 0 \n    best_metrics = None",
        "detail": "grid search.grid_serch_GAT_tox_21",
        "documentation": {}
    },
    {
        "label": "grid_2",
        "kind": 5,
        "importPath": "grid search.grid_serch_GAT_tox_21",
        "description": "grid search.grid_serch_GAT_tox_21",
        "peekOfCode": "grid_2 = ParameterGrid(param_grid_2)\n# Track the best model and performance\nbest_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):\n    best_params = None  \n    best_val_auc = 0 \n    best_metrics = None\n    for params in grid:",
        "detail": "grid search.grid_serch_GAT_tox_21",
        "documentation": {}
    },
    {
        "label": "best_val_auc",
        "kind": 5,
        "importPath": "grid search.grid_serch_GAT_tox_21",
        "description": "grid search.grid_serch_GAT_tox_21",
        "peekOfCode": "best_val_auc = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):\n    best_params = None  \n    best_val_auc = 0 \n    best_metrics = None\n    for params in grid:\n        print(f\"Testing combination ({search_name}): {params}\")\n        if search_name == \"Grid 1\":  # Learning rate scheduler parameters",
        "detail": "grid search.grid_serch_GAT_tox_21",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "grid search.grid_serch_GAT_tox_21",
        "description": "grid search.grid_serch_GAT_tox_21",
        "peekOfCode": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Helper function to run a grid search for both grids\ndef run_grid_search(grid, search_name):\n    best_params = None  \n    best_val_auc = 0 \n    best_metrics = None\n    for params in grid:\n        print(f\"Testing combination ({search_name}): {params}\")\n        if search_name == \"Grid 1\":  # Learning rate scheduler parameters\n            # Default model parameters for grid_1 search",
        "detail": "grid search.grid_serch_GAT_tox_21",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": "grid search.grid_serch_GAT_tox_21",
        "description": "grid search.grid_serch_GAT_tox_21",
        "peekOfCode": "results = {\n    'best_config_lr': best_params_1,\n    'best_metrics_lr': best_metrics_1,\n    'best_config_architecture': best_params_2,\n    'best_metrics_architecture': best_metrics_2\n}\nwith open('grid_search/grid_search_GAT_results.json', 'w') as f:\n    json.dump(results, f, indent=4)\nprint(\"Best configuration and metrics saved to grid_search_GAT_results.json.\")",
        "detail": "grid search.grid_serch_GAT_tox_21",
        "documentation": {}
    },
    {
        "label": "GATTox21",
        "kind": 6,
        "importPath": "model.GAT_tox21",
        "description": "model.GAT_tox21",
        "peekOfCode": "class GATTox21(torch.nn.Module):\n    def __init__(self, num_node_features, num_edge_features, hidden_dim=256, num_heads=2, num_layers=4, dropout=0.5):\n        super(GATTox21, self).__init__()\n        self.node_embedding = torch.nn.Linear(num_node_features, hidden_dim)\n        self.convs = torch.nn.ModuleList()\n        input_dim = hidden_dim\n        for _ in range(num_layers):\n            self.convs.append(GATv2Conv(input_dim, hidden_dim, edge_dim=num_edge_features, heads=num_heads))\n            input_dim = hidden_dim * num_heads\n        self.bn = torch.nn.ModuleList([torch.nn.BatchNorm1d(input_dim) for _ in range(num_layers)])",
        "detail": "model.GAT_tox21",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": "model.GAT_tox21",
        "description": "model.GAT_tox21",
        "peekOfCode": "def calculate_metrics(y_true, y_pred, mask):\n    \"\"\"Calculate various performance metrics.\"\"\"\n    # Convert predictions to binary (0/1)\n    y_pred_binary = (y_pred > 0.5).float()\n    # Apply mask to get valid predictions\n    y_true = y_true[mask]\n    y_pred = y_pred[mask]\n    y_pred_binary = y_pred_binary[mask]\n    # Calculate metrics\n    correct = (y_pred_binary == y_true).float().sum()",
        "detail": "model.GAT_tox21",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "model.GAT_tox21",
        "description": "model.GAT_tox21",
        "peekOfCode": "def train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        if data.edge_weight is not None:\n            data.edge_weight = data.edge_weight.float()",
        "detail": "model.GAT_tox21",
        "documentation": {}
    },
    {
        "label": "validate",
        "kind": 2,
        "importPath": "model.GAT_tox21",
        "description": "model.GAT_tox21",
        "peekOfCode": "def validate(model, val_loader, device, epoch):\n    model.eval()\n    total_loss = 0\n    all_metrics = []\n    all_y_true = []\n    all_y_pred = []\n    for data in val_loader:\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()",
        "detail": "model.GAT_tox21",
        "documentation": {}
    },
    {
        "label": "current_time",
        "kind": 5,
        "importPath": "model.GAT_tox21",
        "description": "model.GAT_tox21",
        "peekOfCode": "current_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\nlog_dir = f'runs/GAT_Tox21_500_epochs{current_time}'\nwriter = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()",
        "detail": "model.GAT_tox21",
        "documentation": {}
    },
    {
        "label": "log_dir",
        "kind": 5,
        "importPath": "model.GAT_tox21",
        "description": "model.GAT_tox21",
        "peekOfCode": "log_dir = f'runs/GAT_Tox21_500_epochs{current_time}'\nwriter = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()",
        "detail": "model.GAT_tox21",
        "documentation": {}
    },
    {
        "label": "writer",
        "kind": 5,
        "importPath": "model.GAT_tox21",
        "description": "model.GAT_tox21",
        "peekOfCode": "writer = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        if data.edge_weight is not None:",
        "detail": "model.GAT_tox21",
        "documentation": {}
    },
    {
        "label": "GCNTox21",
        "kind": 6,
        "importPath": "model.GCN_node_tox21",
        "description": "model.GCN_node_tox21",
        "peekOfCode": "class GCNTox21(torch.nn.Module):\n    def __init__(self, num_node_features, num_edge_features,hidden_dim=256, num_layers=3, dropout=0.2):\n        super(GCNTox21, self).__init__()\n        # Edge embedding layer\n        self.edge_embedding = torch.nn.Linear(num_edge_features, 32)\n        # Node embedding layer\n        self.node_embedding = torch.nn.Linear(num_node_features, hidden_dim)\n        # Dynamically create MLPs and EdgeConv layers\n        self.convs = torch.nn.ModuleList()\n        self.bns = torch.nn.ModuleList()",
        "detail": "model.GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": "model.GCN_node_tox21",
        "description": "model.GCN_node_tox21",
        "peekOfCode": "def calculate_metrics(y_true, y_pred, mask):\n    \"\"\"Calculate various performance metrics.\"\"\"\n    # Convert predictions to binary (0/1)\n    y_pred_binary = (y_pred > 0.5).float()\n    # Apply mask to get valid predictions\n    y_true = y_true[mask]\n    y_pred = y_pred[mask]\n    y_pred_binary = y_pred_binary[mask]\n    # Calculate metrics\n    correct = (y_pred_binary == y_true).float().sum()",
        "detail": "model.GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "model.GCN_node_tox21",
        "description": "model.GCN_node_tox21",
        "peekOfCode": "def train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        if data.edge_weight is not None:\n            data.edge_weight = data.edge_weight.float()",
        "detail": "model.GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "validate",
        "kind": 2,
        "importPath": "model.GCN_node_tox21",
        "description": "model.GCN_node_tox21",
        "peekOfCode": "def validate(model, val_loader, device, epoch):\n    model.eval()\n    total_loss = 0\n    all_metrics = []\n    all_y_true = []\n    all_y_pred = []\n    for data in val_loader:\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()",
        "detail": "model.GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "current_time",
        "kind": 5,
        "importPath": "model.GCN_node_tox21",
        "description": "model.GCN_node_tox21",
        "peekOfCode": "current_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\nlog_dir = f'runs/GCN_node_tox21_{current_time}'\nwriter = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()",
        "detail": "model.GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "log_dir",
        "kind": 5,
        "importPath": "model.GCN_node_tox21",
        "description": "model.GCN_node_tox21",
        "peekOfCode": "log_dir = f'runs/GCN_node_tox21_{current_time}'\nwriter = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()",
        "detail": "model.GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "writer",
        "kind": 5,
        "importPath": "model.GCN_node_tox21",
        "description": "model.GCN_node_tox21",
        "peekOfCode": "writer = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        if data.edge_weight is not None:",
        "detail": "model.GCN_node_tox21",
        "documentation": {}
    },
    {
        "label": "PairwiseEdgeConv",
        "kind": 6,
        "importPath": "model.GCN_tox21",
        "description": "model.GCN_tox21",
        "peekOfCode": "class PairwiseEdgeConv(MessagePassing):\n    def __init__(self, in_channels, edge_channels, out_channels):\n        super(PairwiseEdgeConv, self).__init__(aggr='mean')\n        # MLP for processing concatenated features\n        # Input: [node_i || node_j || edge_attr]\n        self.mlp = torch.nn.Sequential(\n            torch.nn.Linear(2 * in_channels + edge_channels, out_channels * 2),\n            torch.nn.ReLU(),\n            torch.nn.Linear(out_channels * 2, out_channels)\n        )",
        "detail": "model.GCN_tox21",
        "documentation": {}
    },
    {
        "label": "GCNTox21",
        "kind": 6,
        "importPath": "model.GCN_tox21",
        "description": "model.GCN_tox21",
        "peekOfCode": "class GCNTox21(torch.nn.Module):\n    def __init__(self, num_node_features, num_edge_features,  hidden_dim=256, num_layers=3, edge_hidden=16, dropout=0.2):\n        super(GCNTox21, self).__init__()\n         # Edge embedding layer\n        self.edge_embedding = torch.nn.Sequential(\n            torch.nn.Linear(num_edge_features, edge_hidden),\n            torch.nn.ReLU()\n        )\n        # Node embedding layer\n        self.node_embedding = torch.nn.Sequential(",
        "detail": "model.GCN_tox21",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": "model.GCN_tox21",
        "description": "model.GCN_tox21",
        "peekOfCode": "def calculate_metrics(y_true, y_pred, mask):\n    \"\"\"Calculate various performance metrics.\"\"\"\n    # Convert predictions to binary (0/1)\n    y_pred_binary = (y_pred > 0.5).float()\n    # Apply mask to get valid predictions\n    y_true = y_true[mask]\n    y_pred = y_pred[mask]\n    y_pred_binary = y_pred_binary[mask]\n    # Calculate metrics\n    correct = (y_pred_binary == y_true).float().sum()",
        "detail": "model.GCN_tox21",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "model.GCN_tox21",
        "description": "model.GCN_tox21",
        "peekOfCode": "def train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        if data.edge_weight is not None:\n            data.edge_weight = data.edge_weight.float()",
        "detail": "model.GCN_tox21",
        "documentation": {}
    },
    {
        "label": "validate",
        "kind": 2,
        "importPath": "model.GCN_tox21",
        "description": "model.GCN_tox21",
        "peekOfCode": "def validate(model, val_loader, device, epoch):\n    model.eval()\n    total_loss = 0\n    all_metrics = []\n    all_y_true = []\n    all_y_pred = []\n    for data in val_loader:\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()",
        "detail": "model.GCN_tox21",
        "documentation": {}
    },
    {
        "label": "current_time",
        "kind": 5,
        "importPath": "model.GCN_tox21",
        "description": "model.GCN_tox21",
        "peekOfCode": "current_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\nlog_dir = f'runs/GCN_tox21_{current_time}'\nwriter = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()",
        "detail": "model.GCN_tox21",
        "documentation": {}
    },
    {
        "label": "log_dir",
        "kind": 5,
        "importPath": "model.GCN_tox21",
        "description": "model.GCN_tox21",
        "peekOfCode": "log_dir = f'runs/GCN_tox21_{current_time}'\nwriter = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()",
        "detail": "model.GCN_tox21",
        "documentation": {}
    },
    {
        "label": "writer",
        "kind": 5,
        "importPath": "model.GCN_tox21",
        "description": "model.GCN_tox21",
        "peekOfCode": "writer = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        if data.edge_weight is not None:",
        "detail": "model.GCN_tox21",
        "documentation": {}
    },
    {
        "label": "GCNTox21NNConv",
        "kind": 6,
        "importPath": "model.NNConv_tox21",
        "description": "model.NNConv_tox21",
        "peekOfCode": "class GCNTox21NNConv(torch.nn.Module):\n    def __init__(self, num_node_features, num_edge_features, hidden_dim=64, num_heads=2, num_layers=3, dropout=0.2):\n        super(GCNTox21NNConv, self).__init__()\n        # Edge embedding layer\n        self.edge_embedding = torch.nn.Linear(num_edge_features, hidden_dim // 2)\n        # Node embedding layer\n        self.node_embedding = torch.nn.Linear(num_node_features, hidden_dim)\n        # Dynamically create NNConv layers and MLPs\n        self.mlps = torch.nn.ModuleList()\n        self.convs = torch.nn.ModuleList()",
        "detail": "model.NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": "model.NNConv_tox21",
        "description": "model.NNConv_tox21",
        "peekOfCode": "def calculate_metrics(y_true, y_pred, mask):\n    \"\"\"Calculate various performance metrics.\"\"\"\n    # Convert predictions to binary (0/1)\n    y_pred_binary = (y_pred > 0.5).float()\n    # Apply mask to get valid predictions\n    y_true = y_true[mask]\n    y_pred = y_pred[mask]\n    y_pred_binary = y_pred_binary[mask]\n    # Calculate metrics\n    correct = (y_pred_binary == y_true).float().sum()",
        "detail": "model.NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "model.NNConv_tox21",
        "description": "model.NNConv_tox21",
        "peekOfCode": "def train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        if data.edge_weight is not None:\n            data.edge_weight = data.edge_weight.float()",
        "detail": "model.NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "validate",
        "kind": 2,
        "importPath": "model.NNConv_tox21",
        "description": "model.NNConv_tox21",
        "peekOfCode": "def validate(model, val_loader, device, epoch):\n    model.eval()\n    total_loss = 0\n    all_metrics = []\n    all_y_true = []\n    all_y_pred = []\n    for data in val_loader:\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()",
        "detail": "model.NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "current_time",
        "kind": 5,
        "importPath": "model.NNConv_tox21",
        "description": "model.NNConv_tox21",
        "peekOfCode": "current_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\nlog_dir = f'runs/NNConv_{current_time}'\nwriter = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()",
        "detail": "model.NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "log_dir",
        "kind": 5,
        "importPath": "model.NNConv_tox21",
        "description": "model.NNConv_tox21",
        "peekOfCode": "log_dir = f'runs/NNConv_{current_time}'\nwriter = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()",
        "detail": "model.NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "writer",
        "kind": 5,
        "importPath": "model.NNConv_tox21",
        "description": "model.NNConv_tox21",
        "peekOfCode": "writer = SummaryWriter(log_dir)\ndef train(model, train_loader, optimizer, device, epoch):\n    model.train()\n    total_loss = 0\n    all_metrics = []\n    for batch_idx, data in enumerate(train_loader):\n        data = data.to(device)\n        data.x = data.x.float()\n        data.edge_index = data.edge_index.long()\n        if data.edge_weight is not None:",
        "detail": "model.NNConv_tox21",
        "documentation": {}
    },
    {
        "label": "dataset",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "dataset = MoleculeNet(root='data/TOX21', name='TOX21')\ndataset.get_summary()\n#%% Basic Dataset Statistics\nprint(\"\\n=== Basic Dataset Statistics ===\")\nprint(f\"Total number of molecules: {len(dataset)}\")\nprint(f\"Number of node features: {dataset.num_node_features}\")\nprint(f\"Number of edge features: {dataset.num_edge_features}\")\nprint(f\"Number of tasks: {dataset.num_classes}\")\n#%% Graph Statistics\nprint(\"\\n=== Graph Statistics ===\")",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "n_nodes",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "n_nodes = []\nn_edges = []\nnode_degrees = []\nfor data in tqdm(dataset, desc=\"Analyzing graphs\"):\n    n_nodes.append(data.num_nodes)\n    n_edges.append(data.num_edges)\n    degrees = torch.bincount(data.edge_index[0])\n    node_degrees.extend(degrees.tolist())\nprint(f\"Average number of nodes: {np.mean(n_nodes):.2f} ± {np.std(n_nodes):.2f}\")\nprint(f\"Average number of edges: {np.mean(n_edges):.2f} ± {np.std(n_edges):.2f}\")",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "n_edges",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "n_edges = []\nnode_degrees = []\nfor data in tqdm(dataset, desc=\"Analyzing graphs\"):\n    n_nodes.append(data.num_nodes)\n    n_edges.append(data.num_edges)\n    degrees = torch.bincount(data.edge_index[0])\n    node_degrees.extend(degrees.tolist())\nprint(f\"Average number of nodes: {np.mean(n_nodes):.2f} ± {np.std(n_nodes):.2f}\")\nprint(f\"Average number of edges: {np.mean(n_edges):.2f} ± {np.std(n_edges):.2f}\")\nprint(f\"Average node degree: {np.mean(node_degrees):.2f} ± {np.std(node_degrees):.2f}\")",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "node_degrees",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "node_degrees = []\nfor data in tqdm(dataset, desc=\"Analyzing graphs\"):\n    n_nodes.append(data.num_nodes)\n    n_edges.append(data.num_edges)\n    degrees = torch.bincount(data.edge_index[0])\n    node_degrees.extend(degrees.tolist())\nprint(f\"Average number of nodes: {np.mean(n_nodes):.2f} ± {np.std(n_nodes):.2f}\")\nprint(f\"Average number of edges: {np.mean(n_edges):.2f} ± {np.std(n_edges):.2f}\")\nprint(f\"Average node degree: {np.mean(node_degrees):.2f} ± {np.std(node_degrees):.2f}\")\n#%% Visualize distributions",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "node_features",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "node_features = torch.cat([data.x for data in dataset], dim=0).float()\nprint(\"Node Features Statistics:\")\nprint(f\"Feature dimensionality: {node_features.shape[1]}\")\n# Calculate feature statistics\nfeature_means = node_features.mean(dim=0)\nfeature_stds = node_features.std(dim=0)\n#%% Plot feature statistics\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 2, 1)\nplt.bar(range(len(feature_means)), feature_means)",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "feature_means",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "feature_means = node_features.mean(dim=0)\nfeature_stds = node_features.std(dim=0)\n#%% Plot feature statistics\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 2, 1)\nplt.bar(range(len(feature_means)), feature_means)\nplt.title('Mean Values of Node Features')\nplt.xlabel('Feature Index')\nplt.ylabel('Mean Value')\nplt.subplot(1, 2, 2)",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "feature_stds",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "feature_stds = node_features.std(dim=0)\n#%% Plot feature statistics\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 2, 1)\nplt.bar(range(len(feature_means)), feature_means)\nplt.title('Mean Values of Node Features')\nplt.xlabel('Feature Index')\nplt.ylabel('Mean Value')\nplt.subplot(1, 2, 2)\nplt.bar(range(len(feature_stds)), feature_stds)",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "all_labels",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "all_labels = torch.stack([data.y for data in dataset]).squeeze().numpy()\n# Define task names\ntask_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER',\n    'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5',\n    'SR-HSE', 'SR-MMP', 'SR-p53'\n]\n# Calculate correlation matrix (ignoring missing values)\ncorrelation_matrix = np.zeros((len(task_names), len(task_names)))\nfor i in range(len(task_names)):",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "task_names",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "task_names = [\n    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER',\n    'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5',\n    'SR-HSE', 'SR-MMP', 'SR-p53'\n]\n# Calculate correlation matrix (ignoring missing values)\ncorrelation_matrix = np.zeros((len(task_names), len(task_names)))\nfor i in range(len(task_names)):\n    for j in range(len(task_names)):\n        # Get valid indices (where both tasks have values)",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "correlation_matrix",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "correlation_matrix = np.zeros((len(task_names), len(task_names)))\nfor i in range(len(task_names)):\n    for j in range(len(task_names)):\n        # Get valid indices (where both tasks have values)\n        valid_indices = ~np.isnan(all_labels[:, i]) & ~np.isnan(all_labels[:, j])\n        if valid_indices.sum() > 0:\n            correlation_matrix[i, j] = np.corrcoef(\n                all_labels[valid_indices, i],\n                all_labels[valid_indices, j]\n            )[0, 1]",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "missing_values",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "missing_values = []\nfor i, task in enumerate(task_names):\n    # Count missing values\n    missing = np.isnan(all_labels[:, i]).sum()\n    missing_values.append(missing)\nfor i, task in enumerate(task_names):\n    valid_labels = all_labels[:, i][~np.isnan(all_labels[:, i])]\n    pos_rate = (valid_labels == 1).mean() if len(valid_labels) > 0 else 0\n    missing_rate = missing_values[i] / len(dataset)\n    print(f\"\\n{task}:\")",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "all_labels",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "all_labels = np.array([data.y for data in dataset])\nprint(f\"Shape of all_labels: {all_labels.shape}\")\nfor i in range(all_labels.shape[1]):\n    missing = np.isnan(all_labels[:, i]).sum()\n    print(f\"Missing values in column {i}: {missing}\")\n#%% Visualize a sample of molecules\nprint(\"\\n=== Visualize Sample Molecules ===\")\nsample_molecules = [dataset[i] for i in range(10)]\nsample_smiles = [data.smiles for data in sample_molecules]\nsample_mols = [Chem.MolFromSmiles(smiles) for smiles in sample_smiles]",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "sample_molecules",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "sample_molecules = [dataset[i] for i in range(10)]\nsample_smiles = [data.smiles for data in sample_molecules]\nsample_mols = [Chem.MolFromSmiles(smiles) for smiles in sample_smiles]\nimg = Draw.MolsToGridImage(sample_mols, molsPerRow=5, subImgSize=(200, 200))\ndisplay(img)\n#%% Visualize the graph of a sample molecule !!! test\nprint(\"\\n=== Visualize Graph of a Sample Molecule ===\")\nsample_data = dataset[1]  # Take the first molecule as an example\nG = to_networkx(sample_data, node_attrs=['x'], edge_attrs=['edge_attr'])\n# Plot the graph",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "sample_smiles",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "sample_smiles = [data.smiles for data in sample_molecules]\nsample_mols = [Chem.MolFromSmiles(smiles) for smiles in sample_smiles]\nimg = Draw.MolsToGridImage(sample_mols, molsPerRow=5, subImgSize=(200, 200))\ndisplay(img)\n#%% Visualize the graph of a sample molecule !!! test\nprint(\"\\n=== Visualize Graph of a Sample Molecule ===\")\nsample_data = dataset[1]  # Take the first molecule as an example\nG = to_networkx(sample_data, node_attrs=['x'], edge_attrs=['edge_attr'])\n# Plot the graph\nplt.figure(figsize=(10, 10))",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "sample_mols",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "sample_mols = [Chem.MolFromSmiles(smiles) for smiles in sample_smiles]\nimg = Draw.MolsToGridImage(sample_mols, molsPerRow=5, subImgSize=(200, 200))\ndisplay(img)\n#%% Visualize the graph of a sample molecule !!! test\nprint(\"\\n=== Visualize Graph of a Sample Molecule ===\")\nsample_data = dataset[1]  # Take the first molecule as an example\nG = to_networkx(sample_data, node_attrs=['x'], edge_attrs=['edge_attr'])\n# Plot the graph\nplt.figure(figsize=(10, 10))\npos = nx.spring_layout(G)",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "img = Draw.MolsToGridImage(sample_mols, molsPerRow=5, subImgSize=(200, 200))\ndisplay(img)\n#%% Visualize the graph of a sample molecule !!! test\nprint(\"\\n=== Visualize Graph of a Sample Molecule ===\")\nsample_data = dataset[1]  # Take the first molecule as an example\nG = to_networkx(sample_data, node_attrs=['x'], edge_attrs=['edge_attr'])\n# Plot the graph\nplt.figure(figsize=(10, 10))\npos = nx.spring_layout(G)\nnx.draw(G, pos, with_labels=True, node_color='skyblue', edge_color='gray', node_size=500, font_size=10)",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "sample_data",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "sample_data = dataset[1]  # Take the first molecule as an example\nG = to_networkx(sample_data, node_attrs=['x'], edge_attrs=['edge_attr'])\n# Plot the graph\nplt.figure(figsize=(10, 10))\npos = nx.spring_layout(G)\nnx.draw(G, pos, with_labels=True, node_color='skyblue', edge_color='gray', node_size=500, font_size=10)\n# Draw node labels\nnode_labels = {i: f\"{i}\\n{G.nodes[i]['x']}\" for i in G.nodes}\nnx.draw_networkx_labels(G, pos, labels=node_labels, font_size=8)\n# Draw edge labels",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "G",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "G = to_networkx(sample_data, node_attrs=['x'], edge_attrs=['edge_attr'])\n# Plot the graph\nplt.figure(figsize=(10, 10))\npos = nx.spring_layout(G)\nnx.draw(G, pos, with_labels=True, node_color='skyblue', edge_color='gray', node_size=500, font_size=10)\n# Draw node labels\nnode_labels = {i: f\"{i}\\n{G.nodes[i]['x']}\" for i in G.nodes}\nnx.draw_networkx_labels(G, pos, labels=node_labels, font_size=8)\n# Draw edge labels\nedge_labels = {(i, j): f\"{G.edges[i, j]['edge_attr']}\" for i, j in G.edges}",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "pos",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "pos = nx.spring_layout(G)\nnx.draw(G, pos, with_labels=True, node_color='skyblue', edge_color='gray', node_size=500, font_size=10)\n# Draw node labels\nnode_labels = {i: f\"{i}\\n{G.nodes[i]['x']}\" for i in G.nodes}\nnx.draw_networkx_labels(G, pos, labels=node_labels, font_size=8)\n# Draw edge labels\nedge_labels = {(i, j): f\"{G.edges[i, j]['edge_attr']}\" for i, j in G.edges}\nnx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n# Create a legend for node attributes with actual feature names\nnode_feature_names = ['Atomic Number', 'Chirality', 'Degree', 'Formal Charge', 'Num Hs', 'Hybridization']",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "node_labels",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "node_labels = {i: f\"{i}\\n{G.nodes[i]['x']}\" for i in G.nodes}\nnx.draw_networkx_labels(G, pos, labels=node_labels, font_size=8)\n# Draw edge labels\nedge_labels = {(i, j): f\"{G.edges[i, j]['edge_attr']}\" for i, j in G.edges}\nnx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n# Create a legend for node attributes with actual feature names\nnode_feature_names = ['Atomic Number', 'Chirality', 'Degree', 'Formal Charge', 'Num Hs', 'Hybridization']\nnode_attr_legend = {i: node_feature_names[i] for i in range(len(node_feature_names))}\nnode_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in node_attr_legend.items()])\n# Create a legend for edge attributes with actual feature names",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "edge_labels",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "edge_labels = {(i, j): f\"{G.edges[i, j]['edge_attr']}\" for i, j in G.edges}\nnx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n# Create a legend for node attributes with actual feature names\nnode_feature_names = ['Atomic Number', 'Chirality', 'Degree', 'Formal Charge', 'Num Hs', 'Hybridization']\nnode_attr_legend = {i: node_feature_names[i] for i in range(len(node_feature_names))}\nnode_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in node_attr_legend.items()])\n# Create a legend for edge attributes with actual feature names\nedge_feature_names = ['Bond Type', 'Bond Stereo']\nedge_attr_legend = {i: edge_feature_names[i] for i in range(len(edge_feature_names))}\nedge_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in edge_attr_legend.items()])",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "node_feature_names",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "node_feature_names = ['Atomic Number', 'Chirality', 'Degree', 'Formal Charge', 'Num Hs', 'Hybridization']\nnode_attr_legend = {i: node_feature_names[i] for i in range(len(node_feature_names))}\nnode_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in node_attr_legend.items()])\n# Create a legend for edge attributes with actual feature names\nedge_feature_names = ['Bond Type', 'Bond Stereo']\nedge_attr_legend = {i: edge_feature_names[i] for i in range(len(edge_feature_names))}\nedge_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in edge_attr_legend.items()])\n# Display the legends\nplt.gcf().text(0.02, 0.5, f\"Node Attributes:\\n{node_attr_legend_text}\", fontsize=10, verticalalignment='center')\nplt.gcf().text(0.98, 0.5, f\"Edge Attributes:\\n{edge_attr_legend_text}\", fontsize=10, verticalalignment='center', horizontalalignment='right')",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "node_attr_legend",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "node_attr_legend = {i: node_feature_names[i] for i in range(len(node_feature_names))}\nnode_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in node_attr_legend.items()])\n# Create a legend for edge attributes with actual feature names\nedge_feature_names = ['Bond Type', 'Bond Stereo']\nedge_attr_legend = {i: edge_feature_names[i] for i in range(len(edge_feature_names))}\nedge_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in edge_attr_legend.items()])\n# Display the legends\nplt.gcf().text(0.02, 0.5, f\"Node Attributes:\\n{node_attr_legend_text}\", fontsize=10, verticalalignment='center')\nplt.gcf().text(0.98, 0.5, f\"Edge Attributes:\\n{edge_attr_legend_text}\", fontsize=10, verticalalignment='center', horizontalalignment='right')\nplt.title('Graph of a Sample Molecule')",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "node_attr_legend_text",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "node_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in node_attr_legend.items()])\n# Create a legend for edge attributes with actual feature names\nedge_feature_names = ['Bond Type', 'Bond Stereo']\nedge_attr_legend = {i: edge_feature_names[i] for i in range(len(edge_feature_names))}\nedge_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in edge_attr_legend.items()])\n# Display the legends\nplt.gcf().text(0.02, 0.5, f\"Node Attributes:\\n{node_attr_legend_text}\", fontsize=10, verticalalignment='center')\nplt.gcf().text(0.98, 0.5, f\"Edge Attributes:\\n{edge_attr_legend_text}\", fontsize=10, verticalalignment='center', horizontalalignment='right')\nplt.title('Graph of a Sample Molecule')\nplt.show()",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "edge_feature_names",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "edge_feature_names = ['Bond Type', 'Bond Stereo']\nedge_attr_legend = {i: edge_feature_names[i] for i in range(len(edge_feature_names))}\nedge_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in edge_attr_legend.items()])\n# Display the legends\nplt.gcf().text(0.02, 0.5, f\"Node Attributes:\\n{node_attr_legend_text}\", fontsize=10, verticalalignment='center')\nplt.gcf().text(0.98, 0.5, f\"Edge Attributes:\\n{edge_attr_legend_text}\", fontsize=10, verticalalignment='center', horizontalalignment='right')\nplt.title('Graph of a Sample Molecule')\nplt.show()\n# %%",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "edge_attr_legend",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "edge_attr_legend = {i: edge_feature_names[i] for i in range(len(edge_feature_names))}\nedge_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in edge_attr_legend.items()])\n# Display the legends\nplt.gcf().text(0.02, 0.5, f\"Node Attributes:\\n{node_attr_legend_text}\", fontsize=10, verticalalignment='center')\nplt.gcf().text(0.98, 0.5, f\"Edge Attributes:\\n{edge_attr_legend_text}\", fontsize=10, verticalalignment='center', horizontalalignment='right')\nplt.title('Graph of a Sample Molecule')\nplt.show()\n# %%",
        "detail": "tox21_analysis",
        "documentation": {}
    },
    {
        "label": "edge_attr_legend_text",
        "kind": 5,
        "importPath": "tox21_analysis",
        "description": "tox21_analysis",
        "peekOfCode": "edge_attr_legend_text = \"\\n\".join([f\"{k}: {v}\" for k, v in edge_attr_legend.items()])\n# Display the legends\nplt.gcf().text(0.02, 0.5, f\"Node Attributes:\\n{node_attr_legend_text}\", fontsize=10, verticalalignment='center')\nplt.gcf().text(0.98, 0.5, f\"Edge Attributes:\\n{edge_attr_legend_text}\", fontsize=10, verticalalignment='center', horizontalalignment='right')\nplt.title('Graph of a Sample Molecule')\nplt.show()\n# %%",
        "detail": "tox21_analysis",
        "documentation": {}
    }
]